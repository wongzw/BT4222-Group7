{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "print (\"Current date and time : \")\n",
        "print (now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc6XHxLAJeFX",
        "outputId": "77b3b491-cade-4a05-a5f0-a686e2cdc0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current date and time : \n",
            "2022-11-07 08:13:03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nzWmz4_OqMu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVcMj8pSWKEs",
        "outputId": "1e8502b6-5812-4ea6-e6b0-63344459c28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "-FJBpqLWPGhx",
        "outputId": "2e89a041-bbfa-482c-dd0c-de0b5b9d8d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                      id                       name  \\\n",
              "0               0  0gplL1WMoJ6iYaPgMCL0gX                 Easy On Me   \n",
              "1               1  4BI4iNZigfF4SUq13TcFPh   INDUSTRY BABY - EXTENDED   \n",
              "2               2  58UKC45GPNTflCN6nwCUeF                 Fancy Like   \n",
              "3               3  3rmo8F54jFF8OgYsqTxm5d                 Bad Habits   \n",
              "4               4  50nfwKoDiSYg8zOCREWAm5                    Shivers   \n",
              "...           ...                     ...                        ...   \n",
              "56830       56830  4lCAS06lKCJiFVGhHqxCtW              Talk About It   \n",
              "56831       56831  60xDmDoYJytWs5do9aHI0F              Beat the Odds   \n",
              "56832       56832  6bAHtwPD7MBjSD8UmZFsh8                  Geography   \n",
              "56833       56833  0G9CL2p0TP4kTIXroDR326  twin hearts (feat. YURMS)   \n",
              "56834       56834  1S0EjHjqfjjadNWQMxv6rb                      FÃ¡cil   \n",
              "\n",
              "                                                 artists  \\\n",
              "0                                              ['Adele']   \n",
              "1                           ['Lil Nas X', 'Jack Harlow']   \n",
              "2                                       ['Walker Hayes']   \n",
              "3                                         ['Ed Sheeran']   \n",
              "4                                         ['Ed Sheeran']   \n",
              "...                                                  ...   \n",
              "56830                         ['A Boogie Wit da Hoodie']   \n",
              "56831                                      ['Money Man']   \n",
              "56832  ['Chaos Chaos', 'Kevin Hickey', 'Lucas McCross...   \n",
              "56833                            ['ITSOKTOCRY', 'Yurms']   \n",
              "56834                                     ['Kat Dahlia']   \n",
              "\n",
              "                                              artist_ids  track_number  \\\n",
              "0                             ['4dpARuHxo51G3z768sgnrY']             1   \n",
              "1      ['7jVv8c5Fj3E9VhNjxT4snq', '2LIk90788K0zvyj2JJ...             2   \n",
              "2                             ['7sKxqpSqbIzphAKAhrqvlf']             6   \n",
              "3                             ['6eUKZXaKkcviH0Ku9w2n3V']             4   \n",
              "4                             ['6eUKZXaKkcviH0Ku9w2n3V']             2   \n",
              "...                                                  ...           ...   \n",
              "56830                         ['31W5EY0aAly4Qieq6OFu6I']             9   \n",
              "56831                         ['3Rx4PJ7SP6unkOk5elPUK7']             8   \n",
              "56832  ['6D6rjLdxyE5vwhMlkuQq0E', '12Cqmjoj96GR0wFIup...             1   \n",
              "56833  ['2BUUAEl4BwFRA9NBDgMWSf', '2IaEQEZ606L3nZuGnm...             6   \n",
              "56834                         ['1peH5tSqnYm8W6Bo3I5egE']             3   \n",
              "\n",
              "       danceability  energy  key  loudness  ...  rock  soft rock  \\\n",
              "0             0.604   0.366    5    -7.519  ...     0          0   \n",
              "1             0.732   0.708   10    -6.775  ...     0          0   \n",
              "2             0.647   0.765    1    -6.459  ...     0          0   \n",
              "3             0.807   0.893   11    -3.745  ...     0          0   \n",
              "4             0.788   0.859    2    -2.724  ...     0          0   \n",
              "...             ...     ...  ...       ...  ...   ...        ...   \n",
              "56830         0.445   0.584    1    -9.666  ...     0          0   \n",
              "56831         0.787   0.590   10    -7.123  ...     0          0   \n",
              "56832         0.522   0.788   10    -5.926  ...     0          0   \n",
              "56833         0.786   0.609   11    -6.139  ...     0          0   \n",
              "56834         0.869   0.590   11    -4.453  ...     0          0   \n",
              "\n",
              "       southern hip hop  trap  urban contemporary  release_date  \\\n",
              "0                     0     0                   0      14/10/21   \n",
              "1                     0     0                   0       9/10/21   \n",
              "2                     0     0                   0       21/1/22   \n",
              "3                     0     0                   0      29/10/21   \n",
              "4                     0     0                   0      29/10/21   \n",
              "...                 ...   ...                 ...           ...   \n",
              "56830                 0     1                   0       18/6/20   \n",
              "56831                 1     1                   0       20/3/20   \n",
              "56832                 0     0                   0       21/2/20   \n",
              "56833                 0     0                   0       6/11/20   \n",
              "56834                 0     0                   0      30/10/20   \n",
              "\n",
              "       release_month  average_year_success  is_success bert_dense_lyrics  \n",
              "0            2021-10                    38           1          0.677761  \n",
              "1            2021-10                    27           1          0.587171  \n",
              "2            2022-01                    12           1          0.616422  \n",
              "3            2021-10                    22           1          0.596769  \n",
              "4            2021-10                    22           1          0.640173  \n",
              "...              ...                   ...         ...               ...  \n",
              "56830        2020-06                    64           1          0.597523  \n",
              "56831        2020-03                    -1           0          0.596241  \n",
              "56832        2020-02                    -1           0          0.652086  \n",
              "56833        2020-11                    -1           0          0.560518  \n",
              "56834        2020-10                    71           1          0.613869  \n",
              "\n",
              "[56835 rows x 59 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-403e372b-7f2c-4273-b6a2-790719df91f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>artists</th>\n",
              "      <th>artist_ids</th>\n",
              "      <th>track_number</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>...</th>\n",
              "      <th>rock</th>\n",
              "      <th>soft rock</th>\n",
              "      <th>southern hip hop</th>\n",
              "      <th>trap</th>\n",
              "      <th>urban contemporary</th>\n",
              "      <th>release_date</th>\n",
              "      <th>release_month</th>\n",
              "      <th>average_year_success</th>\n",
              "      <th>is_success</th>\n",
              "      <th>bert_dense_lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0gplL1WMoJ6iYaPgMCL0gX</td>\n",
              "      <td>Easy On Me</td>\n",
              "      <td>['Adele']</td>\n",
              "      <td>['4dpARuHxo51G3z768sgnrY']</td>\n",
              "      <td>1</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.366</td>\n",
              "      <td>5</td>\n",
              "      <td>-7.519</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14/10/21</td>\n",
              "      <td>2021-10</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>0.677761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>4BI4iNZigfF4SUq13TcFPh</td>\n",
              "      <td>INDUSTRY BABY - EXTENDED</td>\n",
              "      <td>['Lil Nas X', 'Jack Harlow']</td>\n",
              "      <td>['7jVv8c5Fj3E9VhNjxT4snq', '2LIk90788K0zvyj2JJ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0.732</td>\n",
              "      <td>0.708</td>\n",
              "      <td>10</td>\n",
              "      <td>-6.775</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9/10/21</td>\n",
              "      <td>2021-10</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>0.587171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>58UKC45GPNTflCN6nwCUeF</td>\n",
              "      <td>Fancy Like</td>\n",
              "      <td>['Walker Hayes']</td>\n",
              "      <td>['7sKxqpSqbIzphAKAhrqvlf']</td>\n",
              "      <td>6</td>\n",
              "      <td>0.647</td>\n",
              "      <td>0.765</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.459</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21/1/22</td>\n",
              "      <td>2022-01</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.616422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3rmo8F54jFF8OgYsqTxm5d</td>\n",
              "      <td>Bad Habits</td>\n",
              "      <td>['Ed Sheeran']</td>\n",
              "      <td>['6eUKZXaKkcviH0Ku9w2n3V']</td>\n",
              "      <td>4</td>\n",
              "      <td>0.807</td>\n",
              "      <td>0.893</td>\n",
              "      <td>11</td>\n",
              "      <td>-3.745</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29/10/21</td>\n",
              "      <td>2021-10</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0.596769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>50nfwKoDiSYg8zOCREWAm5</td>\n",
              "      <td>Shivers</td>\n",
              "      <td>['Ed Sheeran']</td>\n",
              "      <td>['6eUKZXaKkcviH0Ku9w2n3V']</td>\n",
              "      <td>2</td>\n",
              "      <td>0.788</td>\n",
              "      <td>0.859</td>\n",
              "      <td>2</td>\n",
              "      <td>-2.724</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>29/10/21</td>\n",
              "      <td>2021-10</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0.640173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56830</th>\n",
              "      <td>56830</td>\n",
              "      <td>4lCAS06lKCJiFVGhHqxCtW</td>\n",
              "      <td>Talk About It</td>\n",
              "      <td>['A Boogie Wit da Hoodie']</td>\n",
              "      <td>['31W5EY0aAly4Qieq6OFu6I']</td>\n",
              "      <td>9</td>\n",
              "      <td>0.445</td>\n",
              "      <td>0.584</td>\n",
              "      <td>1</td>\n",
              "      <td>-9.666</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>18/6/20</td>\n",
              "      <td>2020-06</td>\n",
              "      <td>64</td>\n",
              "      <td>1</td>\n",
              "      <td>0.597523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56831</th>\n",
              "      <td>56831</td>\n",
              "      <td>60xDmDoYJytWs5do9aHI0F</td>\n",
              "      <td>Beat the Odds</td>\n",
              "      <td>['Money Man']</td>\n",
              "      <td>['3Rx4PJ7SP6unkOk5elPUK7']</td>\n",
              "      <td>8</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.590</td>\n",
              "      <td>10</td>\n",
              "      <td>-7.123</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>20/3/20</td>\n",
              "      <td>2020-03</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.596241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56832</th>\n",
              "      <td>56832</td>\n",
              "      <td>6bAHtwPD7MBjSD8UmZFsh8</td>\n",
              "      <td>Geography</td>\n",
              "      <td>['Chaos Chaos', 'Kevin Hickey', 'Lucas McCross...</td>\n",
              "      <td>['6D6rjLdxyE5vwhMlkuQq0E', '12Cqmjoj96GR0wFIup...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.788</td>\n",
              "      <td>10</td>\n",
              "      <td>-5.926</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21/2/20</td>\n",
              "      <td>2020-02</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.652086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56833</th>\n",
              "      <td>56833</td>\n",
              "      <td>0G9CL2p0TP4kTIXroDR326</td>\n",
              "      <td>twin hearts (feat. YURMS)</td>\n",
              "      <td>['ITSOKTOCRY', 'Yurms']</td>\n",
              "      <td>['2BUUAEl4BwFRA9NBDgMWSf', '2IaEQEZ606L3nZuGnm...</td>\n",
              "      <td>6</td>\n",
              "      <td>0.786</td>\n",
              "      <td>0.609</td>\n",
              "      <td>11</td>\n",
              "      <td>-6.139</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6/11/20</td>\n",
              "      <td>2020-11</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.560518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56834</th>\n",
              "      <td>56834</td>\n",
              "      <td>1S0EjHjqfjjadNWQMxv6rb</td>\n",
              "      <td>FÃ¡cil</td>\n",
              "      <td>['Kat Dahlia']</td>\n",
              "      <td>['1peH5tSqnYm8W6Bo3I5egE']</td>\n",
              "      <td>3</td>\n",
              "      <td>0.869</td>\n",
              "      <td>0.590</td>\n",
              "      <td>11</td>\n",
              "      <td>-4.453</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30/10/20</td>\n",
              "      <td>2020-10</td>\n",
              "      <td>71</td>\n",
              "      <td>1</td>\n",
              "      <td>0.613869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>56835 rows Ã 59 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-403e372b-7f2c-4273-b6a2-790719df91f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-403e372b-7f2c-4273-b6a2-790719df91f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-403e372b-7f2c-4273-b6a2-790719df91f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "fname = f\"/content/drive/MyDrive/BT4222/data/feature_eng_combined_v2.csv\"\n",
        "\n",
        "df = pd.read_csv(fname)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S15xz0BAEjD"
      },
      "source": [
        "Training LR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTsU-OhkAiJC"
      },
      "source": [
        "Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TDeKV6uYAddX",
        "outputId": "02513000-bdb4-44c3-c8cc-a09dfc500730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'id', 'name', 'artists', 'artist_ids', 'track_number',\n",
            "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
            "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
            "       'explicit', 'duration_ms', 'date', 'release_date_x', 'lyrics', 'target',\n",
            "       'length_lyrics', 'unique_length_lyrics', 'title_length',\n",
            "       'non_stop_lyrics', 'length_lyrics_non', 'unique_length_lyrics_non',\n",
            "       'sentiment', 'positive', 'neutral', 'negative', 'compound',\n",
            "       'alternative rock', 'country', 'country rock', 'dance pop', 'folk',\n",
            "       'gangster rap', 'hip hop', 'indie rock', 'mellow gold', 'pop',\n",
            "       'pop rap', 'pop rock', 'post-teen pop', 'r&b', 'rap', 'rock',\n",
            "       'soft rock', 'southern hip hop', 'trap', 'urban contemporary',\n",
            "       'release_date', 'release_month', 'average_year_success', 'is_success',\n",
            "       'bert_dense_lyrics'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Feature selection for training\n",
        "print(df.columns)\n",
        "df_model = df.copy().drop(columns=['Unnamed: 0', 'id', 'name', 'artists', 'artist_ids', 'release_date_x', 'release_date', 'date', 'lyrics', 'non_stop_lyrics', 'release_month', 'sentiment'])\n",
        "\n",
        "#Split train and test set\n",
        "X, y = df_model.drop(columns=['target']), df_model['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azZLx9mrA7Fb"
      },
      "source": [
        "Check for imbalanced class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEwH3gFOA2oZ",
        "outputId": "4bae1ec6-99d6-44b5-827b-c608a43ac7af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    48641\n",
              "1     8194\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_model[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcMx-ApeBGiE"
      },
      "source": [
        "Training with SMOTE oversampling minority class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rzzTT0-BNPI",
        "outputId": "121e1f05-439a-4785-b0ee-47a19a14d98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 32660, 1: 32660})\n"
          ]
        }
      ],
      "source": [
        "# Oversample and plot imbalanced dataset with SMOTE\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X_train_smote, y_train_smote = oversample.fit_resample(X_train, y_train)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y_train_smote)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tiuom9GMBYzw"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvETs8M6hwEA",
        "outputId": "6cf973bc-9a53-4f9b-d3b4-36312ae6794b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.857 (0.001)\n"
          ]
        }
      ],
      "source": [
        "# #l2\n",
        "model = LogisticRegression(max_iter=10000, solver=\"sag\", random_state=42)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkgizVV2sVtq",
        "outputId": "aa4ced9c-5ef8-44b7-ba10-2d7367f3e26a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Accuracy: 0.854 (0.010)\n"
          ]
        }
      ],
      "source": [
        "#l2 (lbfgs)\n",
        "model_lbfgs = LogisticRegression(max_iter=10000, random_state=42)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model_lbfgs, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-jAa5lsJzwW",
        "outputId": "1b1f4c6e-bba7-483c-eba7-1d279e3c5159"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=10000, random_state=42, solver='sag')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYu2Clu59-bZ",
        "outputId": "0bf6d22b-adc3-4294-e8fe-8c59bc618d71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=10000, random_state=42)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_lbfgs.fit(X_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g_bO88NJ1qL"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'model_lr_l2_sag.sav'\n",
        "pickle.dump(model, open(f\"/content/drive/My Drive/BT4222/{filename}\", 'wb'))\n",
        "pickle.dump(model_lbfgs, open(f\"/content/drive/My Drive/BT4222/model_lr_l2.sav\", 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtbKYp3QtRwg",
        "outputId": "df5cfd4f-38cd-4b34-98be-513542ce12e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7774578801450203"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rjew0KyaDsxP",
        "outputId": "6f62a529-b965-44b9-9725-b4405ec54615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7935060780550224"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_lbfgs.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVM5KlfttVDo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCazLX-Btc0C"
      },
      "outputs": [],
      "source": [
        "filename = 'model_lr_l2_sag.sav'\n",
        "model = pickle.load(open(f\"/content/drive/My Drive/BT4222/{filename}\", 'rb'))\n",
        "model_lbfgs = pickle.load(open(f\"/content/drive/My Drive/BT4222/model_lr_l2.sav\", 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtUGIztJtgWp"
      },
      "outputs": [],
      "source": [
        "predicted = model.predict(X_test)\n",
        "predicted_lbfgs = model_lbfgs.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG0R-kbAtjYH",
        "outputId": "0f091af5-641c-4e0e-a4ec-96084583d323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.86     15981\n",
            "           1       0.36      0.68      0.47      2775\n",
            "\n",
            "    accuracy                           0.78     18756\n",
            "   macro avg       0.65      0.74      0.67     18756\n",
            "weighted avg       0.85      0.78      0.80     18756\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8ux-rGdEB-F",
        "outputId": "40aa6211-de26-472d-a25b-bc4211493c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.80      0.87     15981\n",
            "           1       0.39      0.73      0.51      2775\n",
            "\n",
            "    accuracy                           0.79     18756\n",
            "   macro avg       0.67      0.77      0.69     18756\n",
            "weighted avg       0.86      0.79      0.82     18756\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, predicted_lbfgs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1OyU_jftmZ_",
        "outputId": "b0068387-b725-4dcf-89e2-79a145bd98aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7774578801450203\n",
            "Precision: 0.3646740181853357\n",
            "Recall: 0.6792792792792792\n",
            "F1-score: 0.47457200402819744\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwmUdE0EH7g",
        "outputId": "76011444-1ef7-4ed2-a23e-50086d7c143f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7935060780550224\n",
            "Precision: 0.393522110162917\n",
            "Recall: 0.7311711711711711\n",
            "F1-score: 0.511663094187366\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted_lbfgs)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted_lbfgs)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted_lbfgs)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted_lbfgs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "5160Ab7ItqOj",
        "outputId": "749f4af8-a780-4c8c-d47b-277837254a36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f368f7cb090>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(model, X_test, y_test)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Ha305OI-EPKg",
        "outputId": "4331fdd8-d12d-4673-afad-7a012e437ef4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f368b2a0550>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(model_lbfgs, X_test, y_test)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIVDDNFqE5YS"
      },
      "source": [
        "Hyperparameter tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "oversample = SMOTE()\n",
        "X_train_smote_scaled, y_train_smote_scaled = oversample.fit_resample(X_train_scaled, y_train)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y_train_smote_scaled)\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTCfeha0iVir",
        "outputId": "8604dcd1-d987-45d7-92ac-a1151fe315b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 32660, 1: 32660})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uIXzx7pEtzA"
      },
      "outputs": [],
      "source": [
        "X_train_temp, X_val_smote, y_train_temp, y_val_smote = train_test_split(X_train_smote, y_train_smote, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAxUHjAbEtzB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "model = LogisticRegression(max_iter=100, random_state=42)\n",
        "# define evaluation\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
        "# define search space\n",
        "space = dict()\n",
        "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
        "space['C'] = loguniform(1e-5, 100)\n",
        "# define search\n",
        "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=42)\n",
        "# execute search\n",
        "result = search.fit(X_train, y_train)\n",
        "# summarize result\n",
        "print('Best Score: %s' % result.best_score_)\n",
        "print('Best Hyperparameters: %s' % result.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMBQcS_HE6xy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# define search\n",
        "grid_search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv, random_state=42)\n",
        "# execute search\n",
        "grid_result = grid_search.fit(X_train_smote, y_train_smote)\n",
        "# summarize result\n",
        "print('Best Score: %s' % grid_result.best_score_)\n",
        "print('Best Hyperparameters: %s' % grid_result.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "\n",
        "space={'C': hp.loguniform('x_C',-10,1),\n",
        "       'solver':  hp.choice('x_solver',[{'solver':'newton-cg', 'penalty': hp.choice('p_newton',['none','l2'])},\n",
        "                                        {'solver':'lbfgs', 'penalty': hp.choice('p_lbfgs',['none','l2'])},\n",
        "                                        {'solver': 'liblinear', 'penalty': hp.choice('p_lib',['l1','l2'])}, \n",
        "                                        {'solver': 'sag', 'penalty': hp.choice('p_sag',['l2','none'])}, \n",
        "                                        {'solver':'saga', 'penalty':'elasticnet'}]),\n",
        "       'tol': hp.loguniform('x_tol',-13,-1),\n",
        "       'l1_ratio': hp.uniform('x_l1',0,1)}\n"
      ],
      "metadata": {
        "id": "DY_8W9q5PpdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bd17rCaQEtzC"
      },
      "outputs": [],
      "source": [
        "def objective(space):\n",
        "    solver=space['solver']['solver']\n",
        "    penalty=space['solver']['penalty']\n",
        "    clf=LogisticRegression(penalty=penalty, C=space['C'], tol=space['tol'], l1_ratio=space['l1_ratio'], solver=solver, max_iter=10000)\n",
        "    clf.fit(X_train, y_train)\n",
        "    acc=clf.score(X_test,y_test)\n",
        "    return {'loss': -acc, 'status': STATUS_OK}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "\n",
        "space = {\n",
        "    # 'warm_start' : hp.choice('warm_start', [True, False]),\n",
        "    # 'fit_intercept' : hp.choice('fit_intercept', [True, False]),\n",
        "    'tol' : hp.uniform('tol', 0.00001, 0.0001),\n",
        "    'C' : hp.uniform('C', 0.05, 3),\n",
        "    'solver' : hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
        "    'max_iter' : hp.choice('max_iter', range(5,1000)),\n",
        "    'l1_ratio': hp.uniform('x_l1',0,1),\n",
        "}\n",
        "\n",
        "def objective(space):\n",
        "    solver=space['solver']\n",
        "    # penalty=space['solver']['penalty']\n",
        "    clf=LogisticRegression(C=space['C'], tol=space['tol'], l1_ratio=space['l1_ratio'], solver=solver, max_iter=space['l1_ratio'])\n",
        "    clf.fit(X_train_smote_scaled, y_train_smote_scaled)\n",
        "    acc=clf.score(X_test_scaled,y_test)\n",
        "    return {'loss': -acc, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "mebgxkGWRmmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9CQv1ruEtzC",
        "outputId": "7628bed1-275c-453a-902f-eefdb1ef6f1e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0%|          | 2/500 [00:00<01:09,  7.14it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1%|          | 3/500 [00:00<01:06,  7.44it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1%|          | 4/500 [00:00<01:28,  5.64it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1%|          | 6/500 [00:00<01:22,  5.96it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2%|â         | 8/500 [00:01<01:27,  5.62it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2%|â         | 9/500 [00:01<01:29,  5.46it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2%|â         | 12/500 [00:02<01:23,  5.84it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  3%|â         | 13/500 [00:02<01:25,  5.69it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3%|â         | 15/500 [00:02<01:23,  5.80it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  3%|â         | 16/500 [00:02<01:26,  5.59it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  4%|â         | 18/500 [00:03<01:27,  5.50it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  4%|â         | 19/500 [00:03<01:22,  5.83it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  4%|â         | 20/500 [00:03<01:36,  4.96it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  4%|â         | 22/500 [00:03<01:21,  5.88it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5%|â         | 24/500 [00:04<01:20,  5.91it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5%|â         | 25/500 [00:04<01:15,  6.28it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5%|â         | 27/500 [00:04<01:17,  6.07it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6%|â         | 28/500 [00:04<01:14,  6.35it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  6%|â         | 30/500 [00:05<01:20,  5.83it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6%|â         | 31/500 [00:05<01:14,  6.28it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7%|â         | 33/500 [00:05<01:21,  5.73it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7%|â         | 35/500 [00:06<01:17,  6.02it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7%|â         | 37/500 [00:06<01:17,  5.97it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8%|â         | 38/500 [00:06<01:13,  6.29it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  8%|â         | 40/500 [00:07<01:20,  5.72it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8%|â         | 41/500 [00:07<01:23,  5.52it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  9%|â         | 43/500 [00:07<01:26,  5.31it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9%|â         | 44/500 [00:07<01:19,  5.75it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9%|â         | 45/500 [00:07<01:24,  5.36it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  9%|â         | 47/500 [00:08<01:21,  5.56it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 10%|â         | 49/500 [00:08<01:19,  5.69it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|â         | 50/500 [00:08<01:22,  5.48it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|â         | 51/500 [00:09<01:31,  4.93it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 11%|â         | 53/500 [00:09<01:18,  5.71it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 11%|â         | 55/500 [00:09<01:17,  5.72it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 11%|â         | 56/500 [00:09<01:21,  5.44it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 12%|ââ        | 58/500 [00:10<01:21,  5.44it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12%|ââ        | 59/500 [00:10<01:15,  5.86it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12%|ââ        | 60/500 [00:10<01:28,  5.00it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 12%|ââ        | 62/500 [00:11<01:22,  5.30it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13%|ââ        | 64/500 [00:11<01:20,  5.41it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13%|ââ        | 66/500 [00:11<01:09,  6.25it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13%|ââ        | 67/500 [00:12<01:20,  5.37it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 14%|ââ        | 69/500 [00:12<01:16,  5.61it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 14%|ââ        | 71/500 [00:12<01:14,  5.76it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 14%|ââ        | 72/500 [00:12<01:09,  6.12it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15%|ââ        | 73/500 [00:13<01:21,  5.26it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 15%|ââ        | 75/500 [00:13<01:12,  5.87it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 15%|ââ        | 77/500 [00:13<01:12,  5.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16%|ââ        | 78/500 [00:13<01:14,  5.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 16%|ââ        | 80/500 [00:14<01:13,  5.71it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16%|ââ        | 81/500 [00:14<01:09,  6.02it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 17%|ââ        | 83/500 [00:14<01:13,  5.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 17%|ââ        | 84/500 [00:15<01:12,  5.76it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 17%|ââ        | 85/500 [00:15<01:23,  4.98it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 17%|ââ        | 87/500 [00:15<01:19,  5.17it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 18%|ââ        | 89/500 [00:16<01:16,  5.38it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 18%|ââ        | 90/500 [00:16<01:10,  5.79it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 18%|ââ        | 92/500 [00:16<01:11,  5.73it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19%|ââ        | 93/500 [00:16<01:06,  6.10it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 19%|ââ        | 95/500 [00:17<01:07,  6.01it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19%|ââ        | 96/500 [00:17<01:12,  5.61it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19%|ââ        | 97/500 [00:17<01:11,  5.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20%|ââ        | 98/500 [00:17<01:18,  5.10it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20%|ââ        | 100/500 [00:18<01:12,  5.52it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20%|ââ        | 102/500 [00:18<01:12,  5.50it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 21%|ââ        | 103/500 [00:18<01:07,  5.90it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 21%|ââ        | 105/500 [00:18<01:07,  5.86it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 21%|ââ        | 106/500 [00:19<01:10,  5.59it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22%|âââ       | 108/500 [00:19<01:12,  5.42it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22%|âââ       | 109/500 [00:19<01:10,  5.53it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22%|âââ       | 111/500 [00:20<01:07,  5.73it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22%|âââ       | 112/500 [00:20<01:02,  6.21it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 23%|âââ       | 114/500 [00:20<01:05,  5.93it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 23%|âââ       | 115/500 [00:20<01:05,  5.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 23%|âââ       | 117/500 [00:21<01:05,  5.87it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24%|âââ       | 118/500 [00:21<01:01,  6.21it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 24%|âââ       | 120/500 [00:21<01:04,  5.91it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24%|âââ       | 121/500 [00:21<01:07,  5.58it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24%|âââ       | 122/500 [00:22<01:16,  4.92it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 25%|âââ       | 124/500 [00:22<01:10,  5.33it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25%|âââ       | 125/500 [00:22<01:19,  4.72it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 25%|âââ       | 127/500 [00:23<01:13,  5.10it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 26%|âââ       | 129/500 [00:23<01:13,  5.08it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 26%|âââ       | 131/500 [00:23<01:01,  6.05it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 26%|âââ       | 132/500 [00:23<01:07,  5.47it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 27%|âââ       | 134/500 [00:24<01:01,  5.92it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 27%|âââ       | 136/500 [00:24<01:05,  5.59it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 27%|âââ       | 137/500 [00:24<01:00,  6.02it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 28%|âââ       | 139/500 [00:25<01:00,  5.98it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28%|âââ       | 140/500 [00:25<00:57,  6.24it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28%|âââ       | 141/500 [00:25<01:09,  5.20it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 29%|âââ       | 143/500 [00:25<01:04,  5.53it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 29%|âââ       | 144/500 [00:26<01:12,  4.91it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 29%|âââ       | 146/500 [00:26<01:06,  5.32it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 30%|âââ       | 148/500 [00:26<01:03,  5.58it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|âââ       | 149/500 [00:26<00:58,  6.05it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 30%|âââ       | 151/500 [00:27<00:58,  6.00it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|âââ       | 152/500 [00:27<00:55,  6.32it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 31%|âââ       | 154/500 [00:27<01:01,  5.64it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31%|âââ       | 155/500 [00:27<00:56,  6.12it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 31%|ââââ      | 157/500 [00:28<01:00,  5.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32%|ââââ      | 158/500 [00:28<00:59,  5.71it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32%|ââââ      | 159/500 [00:28<01:09,  4.94it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 32%|ââââ      | 161/500 [00:29<01:04,  5.22it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32%|ââââ      | 162/500 [00:29<01:01,  5.48it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 33%|ââââ      | 164/500 [00:29<00:58,  5.73it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 33%|ââââ      | 165/500 [00:29<00:54,  6.09it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 33%|ââââ      | 167/500 [00:30<00:54,  6.10it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34%|ââââ      | 168/500 [00:30<00:52,  6.37it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34%|ââââ      | 169/500 [00:30<01:05,  5.02it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 34%|ââââ      | 171/500 [00:30<00:56,  5.81it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 35%|ââââ      | 173/500 [00:31<00:55,  5.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35%|ââââ      | 174/500 [00:31<00:52,  6.21it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35%|ââââ      | 175/500 [00:31<01:02,  5.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 35%|ââââ      | 177/500 [00:31<00:55,  5.81it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 36%|ââââ      | 179/500 [00:32<00:55,  5.83it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36%|ââââ      | 180/500 [00:32<00:52,  6.15it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 36%|ââââ      | 182/500 [00:32<00:55,  5.78it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37%|ââââ      | 183/500 [00:32<00:52,  6.05it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37%|ââââ      | 184/500 [00:33<00:58,  5.38it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 37%|ââââ      | 186/500 [00:33<00:57,  5.46it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 38%|ââââ      | 188/500 [00:33<00:56,  5.48it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38%|ââââ      | 189/500 [00:34<00:52,  5.89it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 38%|ââââ      | 191/500 [00:34<00:53,  5.79it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 39%|ââââ      | 193/500 [00:34<00:48,  6.34it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 39%|ââââ      | 195/500 [00:35<00:49,  6.17it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39%|ââââ      | 196/500 [00:35<00:52,  5.80it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39%|ââââ      | 197/500 [00:35<00:59,  5.12it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 40%|ââââ      | 199/500 [00:35<00:55,  5.42it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|ââââ      | 200/500 [00:36<01:01,  4.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 40%|ââââ      | 202/500 [00:36<00:56,  5.27it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 41%|ââââ      | 203/500 [00:36<01:03,  4.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 41%|ââââ      | 205/500 [00:37<00:53,  5.52it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 41%|âââââ     | 207/500 [00:37<00:51,  5.72it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42%|âââââ     | 208/500 [00:37<00:52,  5.56it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 42%|âââââ     | 210/500 [00:38<00:51,  5.62it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42%|âââââ     | 211/500 [00:38<00:49,  5.81it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 43%|âââââ     | 213/500 [00:38<00:49,  5.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 43%|âââââ     | 214/500 [00:38<00:46,  6.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 43%|âââââ     | 216/500 [00:39<00:48,  5.89it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 43%|âââââ     | 217/500 [00:39<00:45,  6.23it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 44%|âââââ     | 219/500 [00:39<00:47,  5.97it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 44%|âââââ     | 220/500 [00:39<00:45,  6.19it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 44%|âââââ     | 222/500 [00:40<00:47,  5.84it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|âââââ     | 223/500 [00:40<00:50,  5.51it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|âââââ     | 224/500 [00:40<00:56,  4.91it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 45%|âââââ     | 226/500 [00:40<00:52,  5.21it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 46%|âââââ     | 228/500 [00:41<00:55,  4.90it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 46%|âââââ     | 230/500 [00:41<00:50,  5.31it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46%|âââââ     | 231/500 [00:41<00:57,  4.69it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 47%|âââââ     | 233/500 [00:42<00:51,  5.14it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47%|âââââ     | 234/500 [00:42<00:57,  4.61it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 47%|âââââ     | 236/500 [00:42<00:55,  4.75it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 48%|âââââ     | 238/500 [00:43<00:52,  4.98it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 48%|âââââ     | 239/500 [00:43<00:47,  5.45it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 48%|âââââ     | 241/500 [00:43<00:46,  5.58it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 48%|âââââ     | 242/500 [00:44<00:44,  5.83it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 49%|âââââ     | 244/500 [00:44<00:44,  5.72it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49%|âââââ     | 245/500 [00:44<00:42,  5.94it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 49%|âââââ     | 247/500 [00:44<00:44,  5.74it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|âââââ     | 248/500 [00:45<00:46,  5.38it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 50%|âââââ     | 250/500 [00:45<00:45,  5.45it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|âââââ     | 251/500 [00:45<00:42,  5.90it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|âââââ     | 252/500 [00:45<00:51,  4.84it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 51%|âââââ     | 254/500 [00:46<00:42,  5.80it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 51%|âââââ     | 256/500 [00:46<00:42,  5.74it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 52%|ââââââ    | 258/500 [00:46<00:40,  6.02it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52%|ââââââ    | 259/500 [00:47<00:47,  5.07it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 52%|ââââââ    | 261/500 [00:47<00:44,  5.38it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52%|ââââââ    | 262/500 [00:47<00:49,  4.77it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 53%|ââââââ    | 264/500 [00:48<00:42,  5.55it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 53%|ââââââ    | 266/500 [00:48<00:40,  5.72it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 53%|ââââââ    | 267/500 [00:48<00:37,  6.14it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 54%|ââââââ    | 269/500 [00:48<00:38,  5.95it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 54%|ââââââ    | 270/500 [00:49<00:37,  6.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 54%|ââââââ    | 272/500 [00:49<00:38,  5.96it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55%|ââââââ    | 273/500 [00:49<00:36,  6.28it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 55%|ââââââ    | 275/500 [00:49<00:37,  5.98it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55%|ââââââ    | 276/500 [00:50<00:36,  6.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 56%|ââââââ    | 278/500 [00:50<00:37,  5.93it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56%|ââââââ    | 279/500 [00:50<00:35,  6.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 56%|ââââââ    | 281/500 [00:50<00:37,  5.92it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56%|ââââââ    | 282/500 [00:51<00:37,  5.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57%|ââââââ    | 283/500 [00:51<00:45,  4.76it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57%|ââââââ    | 284/500 [00:51<00:43,  4.98it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57%|ââââââ    | 285/500 [00:51<00:41,  5.24it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 57%|ââââââ    | 287/500 [00:52<00:40,  5.28it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58%|ââââââ    | 288/500 [00:52<00:39,  5.38it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 58%|ââââââ    | 290/500 [00:52<00:37,  5.55it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58%|ââââââ    | 291/500 [00:52<00:41,  5.00it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58%|ââââââ    | 292/500 [00:53<00:54,  3.83it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 59%|ââââââ    | 294/500 [00:53<00:44,  4.59it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59%|ââââââ    | 295/500 [00:53<00:39,  5.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59%|ââââââ    | 296/500 [00:54<00:41,  4.93it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 60%|ââââââ    | 298/500 [00:54<00:39,  5.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 60%|ââââââ    | 300/500 [00:54<00:36,  5.47it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60%|ââââââ    | 301/500 [00:55<00:34,  5.76it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 61%|ââââââ    | 303/500 [00:55<00:34,  5.63it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61%|ââââââ    | 304/500 [00:55<00:32,  5.95it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61%|ââââââ    | 305/500 [00:55<00:39,  4.89it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 61%|âââââââ   | 307/500 [00:56<00:33,  5.79it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 62%|âââââââ   | 309/500 [00:56<00:33,  5.78it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62%|âââââââ   | 310/500 [00:56<00:30,  6.13it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62%|âââââââ   | 311/500 [00:56<00:36,  5.18it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 63%|âââââââ   | 313/500 [00:57<00:34,  5.42it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 63%|âââââââ   | 314/500 [00:57<00:39,  4.77it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 63%|âââââââ   | 316/500 [00:57<00:34,  5.41it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 64%|âââââââ   | 318/500 [00:58<00:32,  5.60it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 64%|âââââââ   | 319/500 [00:58<00:30,  5.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 64%|âââââââ   | 321/500 [00:58<00:31,  5.67it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 65%|âââââââ   | 323/500 [00:59<00:27,  6.44it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65%|âââââââ   | 324/500 [00:59<00:33,  5.26it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 65%|âââââââ   | 326/500 [00:59<00:30,  5.77it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 66%|âââââââ   | 328/500 [00:59<00:29,  5.81it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66%|âââââââ   | 329/500 [01:00<00:30,  5.57it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 66%|âââââââ   | 331/500 [01:00<00:29,  5.65it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66%|âââââââ   | 332/500 [01:00<00:28,  5.98it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 67%|âââââââ   | 334/500 [01:01<00:28,  5.89it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 67%|âââââââ   | 335/500 [01:01<00:26,  6.29it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 67%|âââââââ   | 337/500 [01:01<00:26,  6.05it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 68%|âââââââ   | 338/500 [01:01<00:25,  6.26it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 68%|âââââââ   | 340/500 [01:02<00:27,  5.80it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 68%|âââââââ   | 341/500 [01:02<00:26,  6.09it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 69%|âââââââ   | 343/500 [01:02<00:28,  5.46it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69%|âââââââ   | 344/500 [01:02<00:28,  5.46it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69%|âââââââ   | 345/500 [01:03<00:31,  4.85it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 69%|âââââââ   | 347/500 [01:03<00:29,  5.26it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|âââââââ   | 348/500 [01:03<00:32,  4.62it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 70%|âââââââ   | 350/500 [01:04<00:29,  5.03it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|âââââââ   | 351/500 [01:04<00:33,  4.41it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 71%|âââââââ   | 353/500 [01:04<00:29,  4.96it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 71%|âââââââ   | 354/500 [01:04<00:32,  4.48it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 71%|âââââââ   | 356/500 [01:05<00:28,  5.07it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 72%|ââââââââ  | 358/500 [01:05<00:29,  4.73it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 72%|ââââââââ  | 360/500 [01:06<00:26,  5.19it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 72%|ââââââââ  | 362/500 [01:06<00:26,  5.27it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73%|ââââââââ  | 363/500 [01:06<00:24,  5.61it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 73%|ââââââââ  | 365/500 [01:06<00:23,  5.71it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73%|ââââââââ  | 366/500 [01:07<00:21,  6.11it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 74%|ââââââââ  | 368/500 [01:07<00:22,  5.94it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74%|ââââââââ  | 369/500 [01:07<00:23,  5.52it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 74%|ââââââââ  | 371/500 [01:08<00:22,  5.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74%|ââââââââ  | 372/500 [01:08<00:21,  6.03it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 75%|ââââââââ  | 374/500 [01:08<00:21,  5.74it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75%|ââââââââ  | 375/500 [01:08<00:20,  6.07it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 75%|ââââââââ  | 377/500 [01:09<00:21,  5.69it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76%|ââââââââ  | 378/500 [01:09<00:22,  5.37it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 76%|ââââââââ  | 380/500 [01:09<00:21,  5.49it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76%|ââââââââ  | 381/500 [01:09<00:21,  5.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 77%|ââââââââ  | 383/500 [01:10<00:20,  5.65it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 77%|ââââââââ  | 384/500 [01:10<00:19,  6.05it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 77%|ââââââââ  | 386/500 [01:10<00:19,  5.74it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 78%|ââââââââ  | 388/500 [01:11<00:17,  6.44it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 78%|ââââââââ  | 390/500 [01:11<00:17,  6.11it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 78%|ââââââââ  | 391/500 [01:11<00:19,  5.61it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 79%|ââââââââ  | 393/500 [01:12<00:20,  5.24it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79%|ââââââââ  | 394/500 [01:12<00:19,  5.37it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79%|ââââââââ  | 395/500 [01:12<00:21,  4.79it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 79%|ââââââââ  | 397/500 [01:12<00:19,  5.16it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80%|ââââââââ  | 398/500 [01:13<00:21,  4.72it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 80%|ââââââââ  | 400/500 [01:13<00:19,  5.26it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80%|ââââââââ  | 401/500 [01:13<00:22,  4.50it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 81%|ââââââââ  | 403/500 [01:13<00:17,  5.50it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 81%|ââââââââ  | 405/500 [01:14<00:17,  5.54it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 81%|ââââââââ  | 406/500 [01:14<00:15,  5.97it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 82%|âââââââââ | 408/500 [01:14<00:16,  5.66it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 82%|âââââââââ | 409/500 [01:15<00:15,  5.88it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 82%|âââââââââ | 411/500 [01:15<00:15,  5.60it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 82%|âââââââââ | 412/500 [01:15<00:14,  5.87it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 83%|âââââââââ | 414/500 [01:15<00:15,  5.54it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 83%|âââââââââ | 415/500 [01:16<00:14,  5.88it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 83%|âââââââââ | 417/500 [01:16<00:15,  5.52it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 84%|âââââââââ | 418/500 [01:16<00:14,  5.82it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 84%|âââââââââ | 420/500 [01:17<00:14,  5.58it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 84%|âââââââââ | 422/500 [01:17<00:12,  6.22it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 85%|âââââââââ | 424/500 [01:17<00:12,  5.91it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85%|âââââââââ | 425/500 [01:17<00:12,  6.12it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 85%|âââââââââ | 427/500 [01:18<00:12,  6.01it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86%|âââââââââ | 428/500 [01:18<00:11,  6.18it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86%|âââââââââ | 429/500 [01:18<00:12,  5.48it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 86%|âââââââââ | 431/500 [01:18<00:12,  5.64it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 87%|âââââââââ | 433/500 [01:19<00:12,  5.47it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 87%|âââââââââ | 434/500 [01:19<00:12,  5.48it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 87%|âââââââââ | 435/500 [01:19<00:13,  4.78it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 87%|âââââââââ | 437/500 [01:20<00:12,  5.09it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 88%|âââââââââ | 439/500 [01:20<00:11,  5.27it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 88%|âââââââââ | 440/500 [01:20<00:11,  5.08it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 88%|âââââââââ | 442/500 [01:21<00:11,  5.20it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89%|âââââââââ | 443/500 [01:21<00:10,  5.51it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 89%|âââââââââ | 445/500 [01:21<00:10,  5.42it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89%|âââââââââ | 446/500 [01:21<00:09,  5.75it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 90%|âââââââââ | 448/500 [01:22<00:09,  5.53it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90%|âââââââââ | 449/500 [01:22<00:08,  5.88it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 90%|âââââââââ | 451/500 [01:22<00:09,  5.41it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90%|âââââââââ | 452/500 [01:23<00:09,  5.03it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91%|âââââââââ | 453/500 [01:23<00:08,  5.48it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 91%|âââââââââ | 455/500 [01:23<00:08,  5.38it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91%|âââââââââ | 456/500 [01:23<00:07,  5.73it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 92%|ââââââââââ| 458/500 [01:24<00:07,  5.52it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92%|ââââââââââ| 459/500 [01:24<00:07,  5.84it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 92%|ââââââââââ| 461/500 [01:24<00:06,  5.67it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92%|ââââââââââ| 462/500 [01:24<00:06,  5.84it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 93%|ââââââââââ| 464/500 [01:25<00:06,  5.58it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93%|ââââââââââ| 465/500 [01:25<00:06,  5.19it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 93%|ââââââââââ| 467/500 [01:25<00:06,  5.33it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 94%|ââââââââââ| 468/500 [01:25<00:05,  5.79it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 94%|ââââââââââ| 470/500 [01:26<00:05,  5.57it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 94%|ââââââââââ| 471/500 [01:26<00:05,  5.78it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 95%|ââââââââââ| 473/500 [01:26<00:04,  5.44it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95%|ââââââââââ| 474/500 [01:27<00:04,  5.54it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95%|ââââââââââ| 475/500 [01:27<00:05,  4.71it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 95%|ââââââââââ| 477/500 [01:27<00:04,  5.11it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96%|ââââââââââ| 478/500 [01:27<00:04,  4.52it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 96%|ââââââââââ| 480/500 [01:28<00:03,  5.01it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96%|ââââââââââ| 481/500 [01:29<00:06,  2.79it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 97%|ââââââââââ| 483/500 [01:29<00:04,  4.01it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 97%|ââââââââââ| 485/500 [01:29<00:03,  4.65it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 97%|ââââââââââ| 487/500 [01:30<00:02,  5.63it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 98%|ââââââââââ| 489/500 [01:30<00:01,  5.57it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 98%|ââââââââââ| 490/500 [01:30<00:01,  5.77it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 98%|ââââââââââ| 492/500 [01:30<00:01,  5.64it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99%|ââââââââââ| 493/500 [01:31<00:01,  5.84it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99%|ââââââââââ| 494/500 [01:31<00:01,  5.02it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 99%|ââââââââââ| 496/500 [01:31<00:00,  5.13it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|ââââââââââ| 498/500 [01:32<00:00,  5.42it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r100%|ââââââââââ| 499/500 [01:32<00:00,  5.83it/s, best loss: -0.8520473448496481]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|ââââââââââ| 500/500 [01:32<00:00,  5.41it/s, best loss: -0.8520473448496481]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trials = Trials()\n",
        "\n",
        "best_hyperparams_smote = fmin(fn = objective,\n",
        "                        space = space,\n",
        "                        algo = tpe.suggest,\n",
        "                        max_evals = 500,\n",
        "                        trials = trials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kSOS_OOEtzC",
        "outputId": "b120eb71-167a-4731-b610-3fead999aa8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.2331574151340383,\n",
              " 'max_iter': 988,\n",
              " 'solver': 3,\n",
              " 'tol': 2.1073284551232667e-05,\n",
              " 'x_l1': 0.7459657357162148}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "best_hyperparams_smote"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver='liblinear', C=1.2331574151340383, l1_ratio=0.7459657357162148, tol=2.1073284551232667e-05, max_iter=988)\n",
        "model.fit(X_train_smote, y_train_smote)\n",
        "model.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POnd3iEHUBJP",
        "outputId": "c2620a60-96bc-45ba-c020-4b2a2b11618d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1479: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8285881851140968"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKhgPFgAEtzF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'model_lr_tuned_smote.sav'\n",
        "pickle.dump(model, open(f\"/content/drive/My Drive/BT4222/{filename}\", 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATqaOYLeEtzF"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'model_lr_tuned_smote.sav'\n",
        "model = pickle.load(open(f\"/content/drive/My Drive/BT4222/{filename}\", 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTQnrx7QEtzF"
      },
      "outputs": [],
      "source": [
        "predicted = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predicted))"
      ],
      "metadata": {
        "id": "17wfT6ILUIan",
        "outputId": "b31eb988-ccfe-48ff-e3ae-a2a6e1d6579c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.84      0.89     15981\n",
            "           1       0.45      0.73      0.56      2775\n",
            "\n",
            "    accuracy                           0.83     18756\n",
            "   macro avg       0.70      0.79      0.73     18756\n",
            "weighted avg       0.87      0.83      0.84     18756\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "yhVEw-UzEtzG",
        "outputId": "69e9f313-0c74-458f-ffa3-b124dc1a0695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f1a0c46f790>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(model, X_test, y_test)  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOCLYvamhS-x",
        "outputId": "f8cc4327-f751-466e-c3c9-750ae9c50e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8125933034762209\n",
            "Precision: 0.4121974371143806\n",
            "Recall: 0.625945945945946\n",
            "F1-score: 0.49706681928745167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GtYdpCN-EtzG",
        "outputId": "1520be23-b5b9-4379-a801-1333b560a0da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.24372688241224105,\n",
              " 0.3761738797349635,\n",
              " 0.9332953454871558,\n",
              " 0.9988702016670391,\n",
              " 0.5649559099926607,\n",
              " 0.9012388579789987,\n",
              " 0.41216621083860705,\n",
              " 0.818757830570009,\n",
              " 0.49056010086563484,\n",
              " 0.686649344315896,\n",
              " 0.256126146396791,\n",
              " 0.7961469154568739,\n",
              " 0.3719827456333322,\n",
              " 0.27222607428630363,\n",
              " 0.962289157502239,\n",
              " 0.9022125152830192,\n",
              " 0.5743917049856911,\n",
              " 0.9383092078539796,\n",
              " 0.8668930444791438,\n",
              " 0.6590073108632171,\n",
              " 0.3483648235427542,\n",
              " 0.5511374599202626,\n",
              " 0.8880902725644988,\n",
              " 0.7415851530096409,\n",
              " 0.8488899138769384,\n",
              " 0.9241563215957592,\n",
              " 0.10592144366779654,\n",
              " 0.8161623984334986,\n",
              " 0.9477762575632066,\n",
              " 0.9763634441179774,\n",
              " 0.04780482839803224,\n",
              " 0.7120331166584712,\n",
              " 0.40886688806751614,\n",
              " 0.9107476217738851,\n",
              " 0.43334308741380423,\n",
              " 0.5590175604233096,\n",
              " 0.852886548714216,\n",
              " 0.8218412768413127,\n",
              " 0.06881388383047937,\n",
              " 0.9032472523744068,\n",
              " 0.07291884564366868,\n",
              " 0.8150497965874782,\n",
              " 0.43272728728833076,\n",
              " 0.6949736185014836,\n",
              " 0.699470554632461,\n",
              " 0.9792944765056807,\n",
              " 0.9837805277757129,\n",
              " 0.9671178150296161,\n",
              " 0.8805795538549293,\n",
              " 0.46015665910159576,\n",
              " 0.9982971476532634,\n",
              " 0.5695576291393991,\n",
              " 0.7024529068416614,\n",
              " 0.044792769334873195,\n",
              " 0.8905146305042787,\n",
              " 0.9808210438451085,\n",
              " 0.6189036870625018,\n",
              " 0.9549928673851128,\n",
              " 0.7309851857761438,\n",
              " 0.4903123281653894,\n",
              " 0.6897079746756056,\n",
              " 0.9375953483315098,\n",
              " 0.43842503596476856,\n",
              " 0.8263502334199389,\n",
              " 0.019229073843852085,\n",
              " 0.43831749181339785,\n",
              " 0.9438130145004429,\n",
              " 0.2441172194640282,\n",
              " 0.09463250826506686,\n",
              " 0.4193028359535447,\n",
              " 0.33673185871902245,\n",
              " 0.6873003338946397,\n",
              " 0.6788824604079653,\n",
              " 0.865135514968377,\n",
              " 0.7310706429581888,\n",
              " 0.8162221265656174,\n",
              " 0.2227528896315476,\n",
              " 0.8460373695362394,\n",
              " 0.08585346834686614,\n",
              " 0.6190108644417951,\n",
              " 0.673862939049845,\n",
              " 0.9150767547736784,\n",
              " 0.950587086973161,\n",
              " 0.6843073819765458,\n",
              " 0.9266461594756207,\n",
              " 0.868217826243139,\n",
              " 0.8849061122875976,\n",
              " 0.7925867986521593,\n",
              " 0.1285173274614907,\n",
              " 0.7365184111469341,\n",
              " 0.1192812197260269,\n",
              " 0.05164974740618866,\n",
              " 0.784468366939385,\n",
              " 0.5691506444166738,\n",
              " 0.938550354102286,\n",
              " 0.8099870942485765,\n",
              " 0.94671951016216,\n",
              " 0.4534091175465582,\n",
              " 0.3654748336374737,\n",
              " 0.6769938086417724,\n",
              " 0.5870751506928782,\n",
              " 0.8234225357858282,\n",
              " 0.11970543075473239,\n",
              " 0.8215077996774693,\n",
              " 0.8316860945743019,\n",
              " 0.9133361369035401,\n",
              " 0.08268140691557624,\n",
              " 0.7001006386051529,\n",
              " 0.6995859474348121,\n",
              " 0.7249010163897448,\n",
              " 0.7382172330926762,\n",
              " 0.3934366374114324,\n",
              " 0.7476840245936404,\n",
              " 0.1054571752524519,\n",
              " 0.0781613650529901,\n",
              " 0.7330054541895051,\n",
              " 0.809580674830744,\n",
              " 0.6868637181770025,\n",
              " 0.6277851292349492,\n",
              " 0.8959253090581625,\n",
              " 0.6260120577574659,\n",
              " 0.1404473007952367,\n",
              " 0.5647181717778303,\n",
              " 0.8636646271825248,\n",
              " 0.16007151363410943,\n",
              " 0.692132759636833,\n",
              " 0.12836586536313765,\n",
              " 0.9492247392098487,\n",
              " 0.9695062968516962,\n",
              " 0.9807756378272431,\n",
              " 0.9998473012537671,\n",
              " 0.5277667764616245,\n",
              " 0.13428633074834329,\n",
              " 0.49966104926213595,\n",
              " 0.9673196096085506,\n",
              " 0.2539793700059555,\n",
              " 0.6984139674603145,\n",
              " 0.1795577175731261,\n",
              " 0.45664737288554524,\n",
              " 0.503554349273311,\n",
              " 0.19051268326654303,\n",
              " 0.6304064079258165,\n",
              " 0.8206868001067145,\n",
              " 0.4965787539115951,\n",
              " 0.6169999188756795,\n",
              " 0.7597337757426537,\n",
              " 0.045872969606894465,\n",
              " 0.9739021259139866,\n",
              " 0.994524890448956,\n",
              " 0.8053250653452115,\n",
              " 0.9011941560005221,\n",
              " 0.02862004748532687,\n",
              " 0.7938601988652558,\n",
              " 0.4765931518361929,\n",
              " 0.2951870355195869,\n",
              " 0.09019623033362412,\n",
              " 0.7906402188290977,\n",
              " 0.8553902684302879,\n",
              " 0.7591049310317809,\n",
              " 0.71226950224448,\n",
              " 0.811571881186249,\n",
              " 0.08969489870088532,\n",
              " 0.8840539182583219,\n",
              " 0.8374916209589265,\n",
              " 0.9984620881985308,\n",
              " 0.9997232169326649,\n",
              " 0.11857698430914243,\n",
              " 0.8400661462163106,\n",
              " 0.8416081023665317,\n",
              " 0.35986483138951075,\n",
              " 0.9952550535110621,\n",
              " 0.4656422470197502,\n",
              " 0.5690533404057587,\n",
              " 0.9617652526101541,\n",
              " 0.8858180965293114,\n",
              " 0.9203010105099906,\n",
              " 0.7604518439241451,\n",
              " 0.998632542705751,\n",
              " 0.8619744149273372,\n",
              " 0.8350744910428088,\n",
              " 0.629546554068751,\n",
              " 0.918967583879941,\n",
              " 0.8188325138306846,\n",
              " 0.6293875272259737,\n",
              " 0.7463265716675729,\n",
              " 0.93684528866651,\n",
              " 0.781133765139896,\n",
              " 0.711290303262502,\n",
              " 0.7806507290404602,\n",
              " 0.7004008797342586,\n",
              " 0.9143321712372109,\n",
              " 0.2845515868084463,\n",
              " 0.4479066713890889,\n",
              " 0.7578142331630628,\n",
              " 0.7436909681819174,\n",
              " 0.12990780395716472,\n",
              " 0.04752702548164023,\n",
              " 0.9999999985319336,\n",
              " 0.5447397164949155,\n",
              " 0.5878489792815385,\n",
              " 0.6721365813270921,\n",
              " 0.8756065516062367,\n",
              " 0.7060262589436762,\n",
              " 0.9518654888328224,\n",
              " 0.9451733719905999,\n",
              " 0.6665196664964093,\n",
              " 0.0918722565386515,\n",
              " 0.5013366883056471,\n",
              " 0.9840358119316888,\n",
              " 0.6011765317106562,\n",
              " 0.8029870454074883,\n",
              " 0.5599690745423105,\n",
              " 0.992859250304946,\n",
              " 0.8461103026695241,\n",
              " 0.6663121847747531,\n",
              " 0.8787441969208893,\n",
              " 0.9358000306024171,\n",
              " 0.9014521467336688,\n",
              " 0.813945662703721,\n",
              " 0.9930902076930693,\n",
              " 0.7693476036151885,\n",
              " 0.6175865023731312,\n",
              " 0.390859863635835,\n",
              " 0.7953894986674079,\n",
              " 0.9549825448727384,\n",
              " 0.3699703319673374,\n",
              " 0.5487419652002399,\n",
              " 0.5429095899663885,\n",
              " 0.6046829343942604,\n",
              " 0.9377175820198925,\n",
              " 0.8524053185539381,\n",
              " 0.5983245212481787,\n",
              " 0.7630832679786561,\n",
              " 0.8170461261718435,\n",
              " 0.5283734907349096,\n",
              " 0.9363516629267319,\n",
              " 0.49646051319695483,\n",
              " 0.03582232798549578,\n",
              " 0.6997420248404205,\n",
              " 0.43429299007419564,\n",
              " 0.2758951986548036,\n",
              " 0.5320704393001234,\n",
              " 0.2202751441468057,\n",
              " 0.6987783860697084,\n",
              " 0.8226301864568286,\n",
              " 0.6065239186995556,\n",
              " 0.7322220766615137,\n",
              " 0.07700623121920613,\n",
              " 0.6177177209625182,\n",
              " 0.7535592794840476,\n",
              " 0.725605567066884,\n",
              " 0.7609468175698548,\n",
              " 0.9749946572845976,\n",
              " 0.7487095712113707,\n",
              " 0.6737702308360658,\n",
              " 0.4771026028554859,\n",
              " 0.6467285063901607,\n",
              " 0.46480999631085784,\n",
              " 0.3894408213158834,\n",
              " 0.07463108341930158,\n",
              " 0.8870547759185632,\n",
              " 0.0809752915418187,\n",
              " 0.6109160076856628,\n",
              " 0.0263383813082384,\n",
              " 0.03359806117739195,\n",
              " 0.11664851436207602,\n",
              " 0.6967346998605028,\n",
              " 0.6322706116624913,\n",
              " 0.09597919167976476,\n",
              " 0.8431754172878293,\n",
              " 0.9752240771181802,\n",
              " 0.884534337521803,\n",
              " 0.6251528590620196,\n",
              " 0.754722568142736,\n",
              " 0.5896097553158268,\n",
              " 0.9899944287293286,\n",
              " 0.9022624554824448,\n",
              " 0.1013522851977644,\n",
              " 0.6201614158839968,\n",
              " 0.35578037094168546,\n",
              " 0.33905259257066733,\n",
              " 0.365027413121748,\n",
              " 0.07596020721184671,\n",
              " 0.7713890927131992,\n",
              " 0.28250087189421735,\n",
              " 0.48737899334971335,\n",
              " 0.8412299638846117,\n",
              " 0.8992599380509025,\n",
              " 0.5033072868565598,\n",
              " 0.683368490140424,\n",
              " 0.8591647165056201,\n",
              " 0.9473055392362252,\n",
              " 0.7614627339897159,\n",
              " 0.03948886084641812,\n",
              " 0.4329135612345657,\n",
              " 0.7157093961450056,\n",
              " 0.8031278351848063,\n",
              " 0.654646448610289,\n",
              " 0.1302821923063474,\n",
              " 0.8929162342894815,\n",
              " 0.5636308355170738,\n",
              " 0.7561498421210008,\n",
              " 0.8124751895369551,\n",
              " 0.16856740485262622,\n",
              " 0.3531986651946696,\n",
              " 0.804842397925951,\n",
              " 0.6515075115386292,\n",
              " 0.7449721288670712,\n",
              " 0.2972415556331772,\n",
              " 0.1264326545898149,\n",
              " 0.953951125247808,\n",
              " 0.6563119966517277,\n",
              " 0.6122266466564451,\n",
              " 0.891679653493018,\n",
              " 0.4029222404035616,\n",
              " 0.7806634308657248,\n",
              " 0.7584967907857277,\n",
              " 0.061782240147111755,\n",
              " 0.45876541954130845,\n",
              " 0.9331440146432795,\n",
              " 0.41040779918949033,\n",
              " 0.8831610608891325,\n",
              " 0.560799060666539,\n",
              " 0.5475906399382102,\n",
              " 0.21032246239763353,\n",
              " 0.9716883917187792,\n",
              " 0.018752363640362923,\n",
              " 0.9576541489968226,\n",
              " 0.8703243260369724,\n",
              " 0.4456884907843568,\n",
              " 0.5630203847793366,\n",
              " 0.9267081861267323,\n",
              " 0.48075037318499003,\n",
              " 0.3341926345832702,\n",
              " 0.9989870625665059,\n",
              " 0.7027937496201389,\n",
              " 0.7649177145360075,\n",
              " 0.770848552557551,\n",
              " 0.3722516407503813,\n",
              " 0.7519120913848676,\n",
              " 0.594411814998104,\n",
              " 0.06306880320252706,\n",
              " 0.7916615969822306,\n",
              " 0.16850543397089468,\n",
              " 0.8276485899160826,\n",
              " 0.6571784669467627,\n",
              " 0.7460792698180284,\n",
              " 0.057133968710541994,\n",
              " 0.43394458900471466,\n",
              " 0.6577277564764565,\n",
              " 0.9542067467403357,\n",
              " 0.3697780896284185,\n",
              " 0.7179691147092033,\n",
              " 0.6693023054324849,\n",
              " 0.6727149481072934,\n",
              " 0.9087247010146575,\n",
              " 0.01452591444849205,\n",
              " 0.376631455432635,\n",
              " 0.10931649199157478,\n",
              " 0.10089994170346106,\n",
              " 0.06155826829199185,\n",
              " 0.7381767182401195,\n",
              " 0.7801260192568626,\n",
              " 0.8931909608272214,\n",
              " 0.9015262218149668,\n",
              " 0.7805919115526457,\n",
              " 0.7044420279820321,\n",
              " 0.49475000478445075,\n",
              " 0.24824591532493734,\n",
              " 0.06404148503191398,\n",
              " 0.9671291602608548,\n",
              " 0.8026866807832371,\n",
              " 0.8757318988432594,\n",
              " 0.7144162545512528,\n",
              " 0.8560623454350867,\n",
              " 0.4533720342120997,\n",
              " 0.5306324620860303,\n",
              " 0.8665635096750557,\n",
              " 0.9011853887088784,\n",
              " 0.03612146123147131,\n",
              " 0.5250598158607991,\n",
              " 0.02237648393272318,\n",
              " 0.8292657890453795,\n",
              " 0.3790190667436657,\n",
              " 0.8292533996726407,\n",
              " 0.9895201783875828,\n",
              " 0.4841119840983481,\n",
              " 0.951913476965675,\n",
              " 0.8910668608104186,\n",
              " 0.5751164653952798,\n",
              " 0.6807012058847436,\n",
              " 0.12726919851083118,\n",
              " 0.6082159723366918,\n",
              " 0.7738779607007498,\n",
              " 0.796484264631332,\n",
              " 0.06418299333244293,\n",
              " 0.4215732306901746,\n",
              " 0.12004144159695518,\n",
              " 0.9506612889860931,\n",
              " 0.7632705215337,\n",
              " 0.7123759004731924,\n",
              " 0.35631260377834284,\n",
              " 0.14104812760742746,\n",
              " 0.649339865277851,\n",
              " 0.901574174341494,\n",
              " 0.8720085559418724,\n",
              " 0.9528143500522677,\n",
              " 0.9674747117840667,\n",
              " 0.765224507521602,\n",
              " 0.9831066285196417,\n",
              " 0.7662267550357891,\n",
              " 0.040901758375308406,\n",
              " 0.9999999881815377,\n",
              " 0.7924051237832364,\n",
              " 0.4895583430233579,\n",
              " 0.5434974044594729,\n",
              " 0.045045089851776354,\n",
              " 0.49466395583406775,\n",
              " 0.9514251360658311,\n",
              " 0.041691820979365524,\n",
              " 0.8920274416739589,\n",
              " 0.11283865367623624,\n",
              " 0.7372057558002996,\n",
              " 0.7879995747634185,\n",
              " 0.8388575620726203,\n",
              " 0.8572155172072106,\n",
              " 0.7594340492809604,\n",
              " 0.36082511098586445,\n",
              " 0.6944336416044542,\n",
              " 0.3042419186835159,\n",
              " 0.9999694852907502,\n",
              " 0.6092277175627889,\n",
              " 0.990240964120016,\n",
              " 0.6689352860024338,\n",
              " 0.41978805689901133,\n",
              " 0.9324958354638829,\n",
              " 0.9697732309287821,\n",
              " 0.24632353580155553,\n",
              " 0.6864488627155338,\n",
              " 0.5289740524848825,\n",
              " 0.9656923368057622,\n",
              " 0.8003641582658978,\n",
              " 0.8408302645533388,\n",
              " 0.07423184726533572,\n",
              " 0.03441319672935761,\n",
              " 0.8631745822976514,\n",
              " 0.6350283290149867,\n",
              " 0.6921357668214789,\n",
              " 0.763307000708415,\n",
              " 0.5179039385170232,\n",
              " 0.6532609683383049,\n",
              " 0.23201872791102385,\n",
              " 0.7978303177651531,\n",
              " 0.1519056483213609,\n",
              " 0.9080898263082796,\n",
              " 0.2596754399968457,\n",
              " 0.5069885257651554,\n",
              " 0.19416108362741913,\n",
              " 0.1469868024058819,\n",
              " 0.9723591650127155,\n",
              " 0.5483950977245005,\n",
              " 0.42462115396282374,\n",
              " 0.5410726070977476,\n",
              " 0.9358321440496792,\n",
              " 0.9901911235118568,\n",
              " 0.4642279368574196,\n",
              " 0.8636737669337736,\n",
              " 0.8124015028696068,\n",
              " 0.8468695001708185,\n",
              " 0.5055170181718964,\n",
              " 0.5820785444231885,\n",
              " 0.18152939771752952,\n",
              " 0.7863331960592773,\n",
              " 0.19770039670808892,\n",
              " 0.9783686169472287,\n",
              " 0.7576522942570085,\n",
              " 0.9996747522688927,\n",
              " 0.7285523489904346,\n",
              " 0.6654610289367453,\n",
              " 0.7577608841704906,\n",
              " 0.8470139500841989,\n",
              " 0.9248641054075415,\n",
              " 0.43486194379156395,\n",
              " 0.9490641824054986,\n",
              " 0.8140465134493127,\n",
              " 0.7459241561974643,\n",
              " 0.133356520926045,\n",
              " 0.7434760211136819,\n",
              " 0.23012575251318101,\n",
              " 0.9626707729976542,\n",
              " 0.6051620220124538,\n",
              " 0.41168388463930405,\n",
              " 0.9407066416109384,\n",
              " 0.8630411415411432,\n",
              " 0.2144103323751536,\n",
              " 0.8604174802866006,\n",
              " 0.45798223455239817,\n",
              " 0.7253474428882922,\n",
              " 0.8988142367960721,\n",
              " 0.7367213865562171,\n",
              " 0.8032310725866785,\n",
              " 0.9931130237094589,\n",
              " 0.2556337284249468,\n",
              " 0.8913019491631307,\n",
              " 0.6925154586542022,\n",
              " 0.4886553359336294,\n",
              " 0.9897600683356989,\n",
              " 0.25226941859966856,\n",
              " 0.9174382004826954,\n",
              " 0.9859540116413738,\n",
              " 0.03693148963434467,\n",
              " 0.9551311062406136,\n",
              " 0.5429132912330777,\n",
              " 0.8407344118383575,\n",
              " 0.9408975933620439,\n",
              " 0.6600749824131915,\n",
              " 0.7046069080222682,\n",
              " 0.9791594341946134,\n",
              " 0.6936303223800118,\n",
              " 0.8668729417538137,\n",
              " 0.8317753715420211,\n",
              " 0.7383530446715396,\n",
              " 0.6275684461019253,\n",
              " 0.11969131671197342,\n",
              " 0.8498829976985857,\n",
              " 0.011971949176191932,\n",
              " 0.35761503638036574,\n",
              " 0.8047894843040755,\n",
              " 0.08217017408259075,\n",
              " 0.8886199853086061,\n",
              " 0.06012293380526801,\n",
              " 0.29259558040832834,\n",
              " 0.9257221677140697,\n",
              " 0.8684829900945589,\n",
              " 0.17315028962490753,\n",
              " 0.9709795367757731,\n",
              " 0.8104101829246111,\n",
              " 0.8120123389916143,\n",
              " 0.770243587098337,\n",
              " 0.7969491117858944,\n",
              " 0.5634878187623646,\n",
              " 0.9986851237687902,\n",
              " 0.9605923588605184,\n",
              " 0.8741835560225019,\n",
              " 0.929109832060165,\n",
              " 0.48379912300129124,\n",
              " 0.6793770595274679,\n",
              " 0.3821694687397772,\n",
              " 0.4971696479381952,\n",
              " 0.7196798842856191,\n",
              " 0.8846189439690226,\n",
              " 0.9419516238791067,\n",
              " 0.48495332275034464,\n",
              " 0.9353306071962234,\n",
              " 0.7686415884462304,\n",
              " 0.7579857365037465,\n",
              " 0.046282043667644324,\n",
              " 0.19332866845546626,\n",
              " 0.8145531976561459,\n",
              " 0.9570146496180716,\n",
              " 0.3699445849683747,\n",
              " 0.5092405386415657,\n",
              " 0.868258842835322,\n",
              " 0.2988596189388797,\n",
              " 0.9727093365169527,\n",
              " 0.6587944499939308,\n",
              " 0.7634798750563963,\n",
              " 0.48368365102301825,\n",
              " 0.8011416672970005,\n",
              " 0.2507579573512809,\n",
              " 0.906076034159441,\n",
              " 0.801275007243273,\n",
              " 0.7748282856853451,\n",
              " 0.8924318039470297,\n",
              " 0.6715475858460485,\n",
              " 0.4673111234217895,\n",
              " 0.8457853075392241,\n",
              " 0.6816553830980853,\n",
              " 0.7816788020485409,\n",
              " 0.8906904755812183,\n",
              " 0.6436300155985356,\n",
              " 0.12568891501151336,\n",
              " 0.4264166593256248,\n",
              " 0.7995249545931097,\n",
              " 0.7062884753423668,\n",
              " 0.6072220415208847,\n",
              " 0.8376495475939468,\n",
              " 0.3660165375586426,\n",
              " 0.8396901059363748,\n",
              " 0.9995298119566655,\n",
              " 0.5779012819816733,\n",
              " 0.8760257742438113,\n",
              " 0.011746131135977778,\n",
              " 0.8125090318875057,\n",
              " 0.7360529263677896,\n",
              " 0.34869895515099114,\n",
              " 0.9326456888005269,\n",
              " 0.9233627997021121,\n",
              " 0.9951046430001156,\n",
              " 0.04998407857736675,\n",
              " 0.6635675251377804,\n",
              " 0.5785500514875137,\n",
              " 0.5804533389052,\n",
              " 0.6852021270389341,\n",
              " 0.8442366862383521,\n",
              " 0.6203602872744377,\n",
              " 0.10336150514915554,\n",
              " 0.828779792503102,\n",
              " 0.8873610113036889,\n",
              " 0.5878579584014121,\n",
              " 0.9198426625334657,\n",
              " 0.7087287688278795,\n",
              " 0.7113783343292149,\n",
              " 0.04000202126715846,\n",
              " 0.9324597104498628,\n",
              " 0.9484923469180617,\n",
              " 0.8074217749527763,\n",
              " 0.33142533949665487,\n",
              " 0.5731545456586069,\n",
              " 0.06864918030258582,\n",
              " 0.42106598678370233,\n",
              " 0.7938338853943436,\n",
              " 0.7949088637053257,\n",
              " 0.8285557652752941,\n",
              " 0.7411358214453883,\n",
              " 0.8241563711842732,\n",
              " 0.5725068650555565,\n",
              " 0.8650773434003798,\n",
              " 0.7810106936316339,\n",
              " 0.6384217244054187,\n",
              " 0.16076221259732904,\n",
              " 0.9116773767607066,\n",
              " 0.816714509195943,\n",
              " 0.7538125972241817,\n",
              " 0.7523634103136818,\n",
              " 0.5095862073146031,\n",
              " 0.5436045317517169,\n",
              " 0.7067190978286282,\n",
              " 0.7764768924945434,\n",
              " 0.28009267697771667,\n",
              " 0.7966618107743828,\n",
              " 0.9386100070030067,\n",
              " 0.4823257623674715,\n",
              " 0.6462817574054104,\n",
              " 0.9795267708881202,\n",
              " 0.8171202307795093,\n",
              " 0.97762156719841,\n",
              " 0.17949076065174852,\n",
              " 0.42177221487422223,\n",
              " 0.863213886501303,\n",
              " 0.9417853094726846,\n",
              " 0.4517263952466384,\n",
              " 0.821517519650602,\n",
              " 0.05332606687317454,\n",
              " 0.493685392007735,\n",
              " 0.7259251710434019,\n",
              " 0.9999446024609259,\n",
              " 0.8847359505453608,\n",
              " 0.025255213568873613,\n",
              " 0.798207779276176,\n",
              " 0.8538069327275551,\n",
              " 0.33823025169301935,\n",
              " 0.44909724596764655,\n",
              " 0.030224900656881437,\n",
              " 0.939818726318618,\n",
              " 0.6262777868564118,\n",
              " 0.4335532132942247,\n",
              " 0.9349989118227425,\n",
              " 0.5736990170470733,\n",
              " 0.857046285550144,\n",
              " 0.7568428250338815,\n",
              " 0.9024581401306221,\n",
              " 0.04293989383386487,\n",
              " 0.17510203227684717,\n",
              " 0.021222669119046134,\n",
              " 0.4293552916938821,\n",
              " 0.3407681650462113,\n",
              " 0.7073841361468279,\n",
              " 0.784481768985682,\n",
              " 0.7655036901874235,\n",
              " 0.7259913975668246,\n",
              " 0.7755731749696582,\n",
              " 0.9138728847496633,\n",
              " 0.23529121571805944,\n",
              " 0.5038167891420913,\n",
              " 0.8517257564076098,\n",
              " 0.7407043041202168,\n",
              " 0.7564543545277297,\n",
              " 0.7738396428615055,\n",
              " 0.9196225531865614,\n",
              " 0.551232809508403,\n",
              " 0.44594143922671914,\n",
              " 0.8018820354258579,\n",
              " 0.6118329168267095,\n",
              " 0.9262635223874985,\n",
              " 0.92810431557632,\n",
              " 0.6418169019663824,\n",
              " 0.7993348977435124,\n",
              " 0.09600167717793551,\n",
              " 0.895195714023449,\n",
              " 0.44545396445139607,\n",
              " 0.8341928950804921,\n",
              " 0.9479787306842687,\n",
              " 0.8211548580611457,\n",
              " 0.12461209932373019,\n",
              " 0.5578776556427572,\n",
              " 0.7076346330626146,\n",
              " 0.3596808074696536,\n",
              " 0.280756109355644,\n",
              " 0.041614265240963566,\n",
              " 0.33817552123607886,\n",
              " 0.5056262672500285,\n",
              " 0.7675191016655949,\n",
              " 0.5841098702717837,\n",
              " 0.4690332488035739,\n",
              " 0.7979668468485842,\n",
              " 0.7169209872616475,\n",
              " 0.5444802775724664,\n",
              " 0.6932071571368359,\n",
              " 0.6246389376621471,\n",
              " 0.1406420209147059,\n",
              " 0.7324690373473313,\n",
              " 0.7708527724330532,\n",
              " 0.8346296887279061,\n",
              " 0.8722212819455861,\n",
              " 0.7668034708604627,\n",
              " 0.4355150717389995,\n",
              " 0.04041446253659764,\n",
              " 0.704007141523993,\n",
              " 0.8649033047916024,\n",
              " 0.799090701321009,\n",
              " 0.8646383973387608,\n",
              " 0.6781236232369336,\n",
              " 0.8157777722302956,\n",
              " 0.7079328237157485,\n",
              " 0.6726988721658924,\n",
              " 0.9649216759968033,\n",
              " 0.742412177251744,\n",
              " 0.7620806022390163,\n",
              " 0.7428056800213629,\n",
              " 0.28216280579681596,\n",
              " 0.6823013130331332,\n",
              " 0.6783566237281442,\n",
              " 0.5107204411547562,\n",
              " 0.28722508055328755,\n",
              " 0.4520030884094055,\n",
              " 0.9681638146138674,\n",
              " 0.6643518992639115,\n",
              " 0.7269475328658543,\n",
              " 0.7876176747405597,\n",
              " 0.9994444211833337,\n",
              " 0.7661165914673796,\n",
              " 0.10391584943763987,\n",
              " 0.5657197207454772,\n",
              " 0.9826375521065251,\n",
              " 0.6621440180434989,\n",
              " 0.36009159744906605,\n",
              " 0.7719707562236228,\n",
              " 0.5541777450136545,\n",
              " 0.44124997668658605,\n",
              " 0.6152277537199533,\n",
              " 0.19783568749613356,\n",
              " 0.0786527383229092,\n",
              " 0.23943130409788538,\n",
              " 0.5629676545179293,\n",
              " 0.12697823717762402,\n",
              " 0.8879996629023281,\n",
              " 0.6894659985110945,\n",
              " 0.8346321012799369,\n",
              " 0.6565441987182321,\n",
              " 0.9272119629550695,\n",
              " 0.9813955066056884,\n",
              " 0.16019655290453783,\n",
              " 0.9115258018002607,\n",
              " 0.7090934471703452,\n",
              " 0.6470265187414366,\n",
              " 0.5053169628754678,\n",
              " 0.5647131966434096,\n",
              " 0.46441247712556444,\n",
              " 0.5292904758333525,\n",
              " 0.5256943782562197,\n",
              " 0.26246184219450597,\n",
              " 0.9721730205327358,\n",
              " 0.2580259923213669,\n",
              " 0.8273615510586467,\n",
              " 0.3040777723589052,\n",
              " 0.2934446253681565,\n",
              " 0.8591059720507062,\n",
              " 0.9002278355000848,\n",
              " 0.042731057452793486,\n",
              " 0.6683687817566384,\n",
              " 0.9079059167715609,\n",
              " 0.5941303086657039,\n",
              " 0.7174531272406748,\n",
              " 0.910000587705559,\n",
              " 0.3062163680556549,\n",
              " 0.47227403348246544,\n",
              " 0.6136187176597666,\n",
              " 0.8574388680599324,\n",
              " 0.6719077645057954,\n",
              " 0.8042902515182158,\n",
              " 0.33474629043635007,\n",
              " 0.7456574940900658,\n",
              " 0.09528921628861986,\n",
              " 0.7592509103096401,\n",
              " 0.8974388734654786,\n",
              " 0.9462579724731432,\n",
              " 0.7375736689046745,\n",
              " 0.8759318877113661,\n",
              " 0.6116553245344181,\n",
              " 0.9655829750680931,\n",
              " 0.6464410812252485,\n",
              " 0.8672697890793293,\n",
              " 0.6176750819446808,\n",
              " 0.7490206214522845,\n",
              " 0.9118464395276407,\n",
              " 0.8208873438945749,\n",
              " 0.7233050149519775,\n",
              " 0.8424976494336515,\n",
              " 0.45539870681372774,\n",
              " 0.7020995854226548,\n",
              " 0.5496966401516061,\n",
              " 0.911736972893023,\n",
              " 0.8664515619998995,\n",
              " 0.6501813806563194,\n",
              " 0.4629919448119706,\n",
              " 0.8582790534694869,\n",
              " 0.2443711421632705,\n",
              " 0.5450118783192963,\n",
              " 0.8701760169141326,\n",
              " 0.5731821397514665,\n",
              " 0.7709684641905843,\n",
              " 0.06173673044885997,\n",
              " 0.7674001449673044,\n",
              " 0.980889948734168,\n",
              " 0.8820054611932677,\n",
              " 0.9296066546161734,\n",
              " 0.3340265530550316,\n",
              " 0.9004914508611334,\n",
              " 0.05238162360360754,\n",
              " 0.3638447067140693,\n",
              " 0.4167450286291453,\n",
              " 0.7881448053932636,\n",
              " 0.7229694269054707,\n",
              " 0.8275375843932165,\n",
              " 0.9054419357781909,\n",
              " 0.5646240277367958,\n",
              " 0.02503762295451417,\n",
              " 0.8369529567121501,\n",
              " 0.5825896198539653,\n",
              " 0.6119384854716963,\n",
              " 0.31725979015473105,\n",
              " 0.6273809736703215,\n",
              " 0.9839633099653186,\n",
              " 0.6177947463738884,\n",
              " 0.9332185399959007,\n",
              " 0.6181927386928733,\n",
              " 0.053994909029342564,\n",
              " 0.5380624573409241,\n",
              " 0.5732925673334022,\n",
              " 0.7104019407365132,\n",
              " 0.9350262735735134,\n",
              " 0.2569782457518133,\n",
              " 0.06276590985143937,\n",
              " 0.8792020418486909,\n",
              " 0.5193368354786602,\n",
              " 0.7965731758871344,\n",
              " 0.30655427622715103,\n",
              " 0.3837145430770741,\n",
              " 0.42576960868926894,\n",
              " 0.7799046819450591,\n",
              " 0.889258910744721,\n",
              " 0.9689703220181045,\n",
              " 0.7722950581044703,\n",
              " 0.7278528374754061,\n",
              " 0.6333608233197803,\n",
              " 0.6956133642908386,\n",
              " 0.4029509574355884,\n",
              " 0.4463048920153948,\n",
              " 0.013525181833297095,\n",
              " 0.9388092407621017,\n",
              " 0.6851009517542235,\n",
              " 0.6688389150558908,\n",
              " 0.5088555553094785,\n",
              " 0.3021506034515429,\n",
              " 0.6716787579315071,\n",
              " 0.04355108905349514,\n",
              " 0.723327899743732,\n",
              " 0.7485201829580552,\n",
              " 0.06869318375179234,\n",
              " 0.1853330569909728,\n",
              " 0.06908615839563825,\n",
              " 0.48857088000381266,\n",
              " 0.7146485011308852,\n",
              " 0.8323112201655487,\n",
              " 0.7535719028871187,\n",
              " 0.6525525657511605,\n",
              " 0.23430479481824795,\n",
              " 0.8996432205490216,\n",
              " 0.5851948968646524,\n",
              " 0.609189929857884,\n",
              " 0.6087163184485447,\n",
              " 0.029410922466525213,\n",
              " 0.9119195041663055,\n",
              " 0.9473645032501548,\n",
              " 0.749813011920703,\n",
              " 0.6055936338681545,\n",
              " 0.513203330693456,\n",
              " 0.24503859829503494,\n",
              " 0.24843880460961731,\n",
              " 0.15026329884862988,\n",
              " 0.3354670092650326,\n",
              " 0.9983352368923231,\n",
              " 0.8165270852463693,\n",
              " 0.7191676432382144,\n",
              " 0.09905507716319717,\n",
              " 0.04192617705158497,\n",
              " 0.9184281718043366,\n",
              " 0.7941486634048652,\n",
              " 0.6693762212775018,\n",
              " 0.8861164037109202,\n",
              " 0.9670670908957091,\n",
              " 0.939376686204578,\n",
              " 0.44730330620738235,\n",
              " 0.32106526949772274,\n",
              " 0.9762540650352521,\n",
              " 0.17216788470000288,\n",
              " 0.9471406212942712,\n",
              " 0.7350141431022703,\n",
              " 0.8823038763078633,\n",
              " 0.8919969172531526,\n",
              " 0.7504933137725047,\n",
              " 0.8743985368453431,\n",
              " 0.09148772825851836,\n",
              " 0.9450003134747778,\n",
              " 0.8925605781776461,\n",
              " 0.9399581558003054,\n",
              " 0.2636580968953476,\n",
              " 0.5089281607889536,\n",
              " 0.11304490588357763,\n",
              " 0.9409196326292469,\n",
              " 0.8612620245934226,\n",
              " 0.9356693711373265,\n",
              " 0.5125450508457803,\n",
              " 0.8203675839699269,\n",
              " 0.22158800759764663,\n",
              " 0.6993621572615862,\n",
              " 0.7137857555195695,\n",
              " 0.9638878752135179,\n",
              " 0.8005513187910405,\n",
              " 0.9393834972853412,\n",
              " 0.6787235029051788,\n",
              " 0.1720565757721959,\n",
              " 0.6833936731481132,\n",
              " 0.2122303439630554,\n",
              " 0.5629686867761783,\n",
              " 0.22952371286846618,\n",
              " 0.40293821669188623,\n",
              " 0.7188439796151235,\n",
              " 0.8259236261996888,\n",
              " 0.7189950658346962,\n",
              " 0.7548394956084981,\n",
              " 0.8463022801960522,\n",
              " 0.6626188732758242,\n",
              " 0.08279009390604364,\n",
              " 0.8206762114825814,\n",
              " 0.3115793193133709,\n",
              " 0.8128579459765931,\n",
              " 0.7194485240584558,\n",
              " 0.733774915782558,\n",
              " 0.9198053148780316,\n",
              " 0.01883252999787821,\n",
              " 0.0887207957116688,\n",
              " 0.9744862843633924,\n",
              " 0.36431596079100026,\n",
              " 0.5062819388150948,\n",
              " 0.24576775579559407,\n",
              " 0.8629759460264443,\n",
              " 0.8316680206457825,\n",
              " 0.6865834737842889,\n",
              " 0.7736718368800979,\n",
              " 0.6572328007791346,\n",
              " 0.7521805022029648,\n",
              " 0.4715786919006326,\n",
              " 0.3179634337038918,\n",
              " 0.09498794877242467,\n",
              " 0.9169491455791127,\n",
              " 0.5717089432009761,\n",
              " 0.9923864527631105,\n",
              " 0.6983689799907423,\n",
              " 0.06886961285225024,\n",
              " 0.655493928243774,\n",
              " 0.7823730349551579,\n",
              " 0.8907964160108779,\n",
              " 0.9302009234206171,\n",
              " 0.7573976715794358,\n",
              " 0.5408283272906755,\n",
              " 0.8033212912762913,\n",
              " 0.7311603855475205,\n",
              " 0.9334579498701985,\n",
              " ...]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[i[0] for i in model.predict_proba(X_test)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euAv34yfEtzH",
        "outputId": "69bf6404-9d9e-47ae-e7bc-62f3e84584c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.797853624208304\n",
            "Precision: 0.3847695390781563\n",
            "Recall: 0.7164179104477612\n",
            "F1-score: 0.5006518904823989\n",
            "ROCAUC-score: 0.8333239030258544\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted)}\")\n",
        "print(f\"ROCAUC-score: {roc_auc_score(y_test, [i[1] for i in model.predict_proba(X_test)])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzT6f4mKkqee",
        "outputId": "6930b52b-d521-4572-98c9-6fb924736992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8743868628705481\n",
            "Precision: 0.5632739353669586\n",
            "Recall: 0.6720720720720721\n",
            "F1-score: 0.6128820243181072\n",
            "ROCAUC-score: 0.8909652847892008\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted)}\")\n",
        "print(f\"ROCAUC-score: {roc_auc_score(y_test, [i[1] for i in model.predict_proba(X_test)])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZh9XrI0kqeg"
      },
      "source": [
        "Oversampling training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AEynE5hkqeh",
        "outputId": "fb8d0ad9-64e6-4fb5-f77a-531c88bec393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 32660, 1: 5419})\n",
            "Counter({0: 32660, 1: 32660})\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "print(Counter(y_train))\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
        "print(Counter(y_train_over))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9c484jykqei",
        "outputId": "00e4fd08-1eb7-4287-cb6b-c25ff5f2b8b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7862017487737257"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_over = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_over.fit(X_train_over, y_train_over)\n",
        "model_over.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN3ZtTPmkqei"
      },
      "outputs": [],
      "source": [
        "predicted_over = model_over.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0332f1wkqei",
        "outputId": "3378e6ee-db88-4b6e-d110-bfcb176844e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7862017487737257\n",
            "Precision: 0.3851162790697674\n",
            "Recall: 0.745945945945946\n",
            "F1-score: 0.5079754601226995\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted_over)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted_over)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted_over)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted_over)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "gPChPw7Tkqej",
        "outputId": "04063265-19c8-473b-a49d-0df5839e0abc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f368fa6b4d0>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZxWdZ3/8dd7hnvlHkHkRjHRxNsUwZsyRFfQbUNb86badc3SSsstd03q94vSLKvdtbTUSFm1zPtKKhPv8i5FRTRTjEAQAUEchvs7mZnP/nG+M1wQzFzXMBfXzDXv5+NxHnPO93zPOd8DzIfv3TlHEYGZmWUqSl0AM7PWxEHRzCyHg6KZWQ4HRTOzHA6KZmY5OpS6ALn69amMfYZ0LHUxrACz3+xX6iJYATZuWMHm99ZpZ84x7oTdYnl1bV55X3xl07SIGL8z19vVWlVQ3GdIR56fNqTUxbACnHDeZ0pdBCvAzGeu2+lzLK+u5flpQ/PKWzlwTpv7X7NVBUUza/0CqKOu1MUoGgdFMytIEGyO/JrPbZGDopkVzDVFM7MkCGrL+PFgB0UzK1gdDopmZkA20FLroGhmtkU51xT9RIuZFSSAzRF5LU2RNEXSMkmv5qT9QNJfJb0i6deSeuXsmyhprqTZksblpI9PaXMlXZ6TPkzScyn9LkmdmiqTg6KZFSQIavNc8nALsO0TLw8DB0fEocDfgIkAkkYAZwMHpWOul1QpqRL4CXAKMAI4J+UF+B5wTUTsB6wAzm+qQA6KZlaYgNo8lyZPFfEkUL1N2kMRUZM2pwOD0/oE4M6I2BQR84G5wKi0zI2IeRHxHnAnMEGSgLHAven4W4HTmiqTg6KZFSR7oiW/pQV8GvhDWh8ELMzZtyil7Si9L7AyJ8DWpzfKAy1mViBRS97vlOgnaUbO9uSImJzXVaSvAzXA7QUWcKc4KJpZQbKBlryDYlVEjCz0GpL+DfgIcGJs+ZDUYiD3jTGDUxo7SF8O9JLUIdUWc/PvkJvPZlaQbJ6i8lqaQ9J44DLgoxGxPmfXVOBsSZ0lDQOGA88DLwDD00hzJ7LBmKkpmP4ROCMdfy5wf1PXd03RzApWl39NsVGS7gDGkDWzFwGTyEabOwMPZ2MlTI+Iz0XEa5LuBmaRNasvisjeTCHpYmAaUAlMiYjX0iW+Ctwp6dvAS8DNTZXJQdHMClJfU2yRc0Wcs53kHQauiLgKuGo76Q8AD2wnfR7Z6HTeHBTNrCCBqC3jnjcHRTMrWEs1n1sjB0UzK0gg3ovKUhejaBwUzawg2eRtN5/NzBq01EBLa+SgaGYFiRC14ZqimVmDOtcUzcwy2UBL+YaO8r0zMysKD7SYmW2j1vMUzcwyfqLFzGwbdR59NjPLZC+EcFA0MwOy5vNmP+ZnZpaJwJO3zcy2kCdvm5nVC1xTNDPbigdazMySQH7JrJlZvewTp+UbOsr3zsysSJr/+dK2wEHRzAoS+IkWM7OtuKZoZpZEyDVFM7N62UCLH/MzM0v8jRYzswbZQIv7FM3MGpTzEy3le2dmVhT1T7TkszRF0hRJyyS9mpPWR9LDkuakn71TuiRdK2mupFckHZFzzLkp/xxJ5+akHynpL+mYayU1WSgHRTMrWB0VeS15uAUYv03a5cCjETEceDRtA5wCDE/LBcANkAVRYBIwGhgFTKoPpCnPZ3OO2/Zaf8dB0cwKEgGb6yryWpo+VzwJVG+TPAG4Na3fCpyWk35bZKYDvSQNBMYBD0dEdUSsAB4Gxqd9PSJiekQEcFvOuXbIfYpmVpCs+Zx3faqfpBk525MjYnITxwyIiCVpfSkwIK0PAhbm5FuU0hpLX7Sd9EY5KJpZwQp4oqUqIkY29zoREZKiucc3h4Ninv77y0N47pEe9OpXw+Q/zgbgZ1fsxfSHe9CxUzBw701ces1Cdu9ZC8C8WV249qtDWLemgooKuO6Bv1FTIy49bXjDOauWdGTsP6/g81csBuCJqb34xX/vCQr2HbGRidcv2PU3WqY6dqjhRxN/T6cOdVRW1vHEjGHc8psj+M/znuKAfapAwaKlPbn65uPZuKkjHTvUMvGzT7D/3lWsXtuFb91wAu8s786Avmu49Tv3sXBpTwBmvdGfa247rsR3t2vtgik570gaGBFLUhN4WUpfDAzJyTc4pS0GxmyT/nhKH7yd/I0qalCUNB74EVAJ3BQRVxfzesV08lnVfPS8Kn5wydCGtCOOX8Onv/Y2lR3gpm8P5M7r+vOZ/7eE2hr4/hf35j+vXcD7DtrI6upKKjsGnboENzwyu+H4i8btzwdPXQnA4nmduOu6/vzP/XPo3quWlVX+/6olba6p5CvfP5WNmzpSWVnHdRN/x3OvDOYnd4xm/cZOAHzh7OmcfuIs7njgME790GzWrOvMpy4/kxNGvcGFZ77AFTeMBeDtZd357KTTS3k7JVb0x/ymAucCV6ef9+ekXyzpTrJBlVUpcE4DvpMzuHIyMDEiqiWtlnQ08Bzwr8B1TV28aHcmqRL4CdmI0QjgHEkjinW9Yjvk6HV07127VdqRY9ZQmWLXgUeup2pJRwBefKI7ww7cwPsO2ghAjz61VG7zVNSiNzqzsqoDB49eB8Afbu/LP/1bFd17Zdfo1a+miHfTHomNm7K/nw6VdVR2qANoCIgQdOpYS3077bgj3mLan/YD4IkZwzjiwLeBXdqKa9Xq0ndamlqaIukO4FngAEmLJJ1PFgz/QdIc4KS0DfAAMA+YC/wM+AJARFQDVwIvpOWKlEbKc1M65g3gD02VqZjVkVHA3IiYB5Ci+wRgVhGvWTLT7ujDhydktb5F87ogwdfO2ZdVyzvw4QkrOfOiZVvlf/z+Xnz4oyupnzW1aF4XAL780f2oqxOfunQpR52wZpfeQ7mrUB0//eb9DOq/mt88diCvz+sPwGWffpLRhy5kwdu9ueGu0QD067WOZdW7A1BXV8HaDZ3osfsmAPbcYy2Tv/lr1m/oxM2/OpK/zNmzNDdUItnoc8s8+xwR5+xg14nbyRvARTs4zxRgynbSZwAHF1KmYgbF7Y0Ijd42k6QLyOYcMXRQ22wy/vJHA6jsEIz92AoAamvg1ed347oH/kbnrnVcftZ+DD90PR/40NqGY564vzeXXbelz7C2FhbP78wP7ptL1ZJOXHr6fvz0sdkNfZS28+qigs9OOp3dum7iyi8+yj6DqnlzcR++P+V4KlTHlz71LCeMmseDT++/w3NUr+rG2Zeexep1Xdh/7yqu/NIjnPf1j+XUOMtfuX+OoOTzFCNickSMjIiRe/Rte2/eeOiuPjz/SA+++uMFDbW+PQZu5pCj19Gzby1dugVHjV3N3L90bTjmjde6UFsLww/d0JDWb+Bmjj55NR06wp5D32Pw+zaxeH77+UXbldZt6MzLfx3IqEO29LnXRQWPPbcvxx/5JgBVK3ejf5/sP7GKijp27/oeq9d2ZnNNJavXZbX6vy3ox9vLujN4z1W7/B5KraWaz61RMYPijkaKysYLf+zOPdf355u3zKNLty39TUeOWcObr3dh43pRWwOvPLs7Q/ff1LD/8d/0Zkxqatc7dvwqXnk2a66tWl7Jojc6M3Doe7vmRtqBnt03sFvX7O+gU8cajjxoMQuX9GSv/qtTjuDYD7zFW2lU+ZmXhjLuuLkAfHjkfF56fS9A9Oy+gQpl/ZED91jNoAGrWfJuj119OyVVP/rcEo/5tUbFbK++AAyXNIwsGJ4NfKKI1yuq735+b155dndWVXfgk0eO4F8uXcqdPx7A5k1i4llZh/z7j1zHJd9bRPdetXzswnf54qn7I8GosasZfdLqhnM9+dteXPnzeVudf+SYNcx8ojuf/fD7qagMPvv/36ZHHzedW0rfnhu4/DNPUFERVCh4/IV9mf7KEK6d+Du6dd2MCN5Y2JdrbjsWgN8/uT9fu+AJfnH13axe15krbzwBgMP2X8p5p8+kpraCuhDX3Hoca9Z1LuWtlUQ5v2RWWd9lkU4unQr8kGxKzpSIuKqx/CMP6xLPTxvSWBZrZU447zOlLoIVYOYz17Fm1aKdqsL1fn//GDvljLzy/uq4G17cmcnbpVDUkY2IeIBsGN3MykhbbRrno20O95pZyfgls2Zm23BQNDNLyn2eooOimRWsrc5BzIeDopkVJAJq8niBbFvloGhmBXPz2cwscZ+imdk2wkHRzGwLD7SYmSUR7lM0M8shaj36bGa2hfsUzcwSP/tsZpYrsn7FcuWgaGYF8+izmVkSHmgxM9uam89mZjk8+mxmlkQ4KJqZbcVTcszMcpRzn2L5DiGZWVEEoq6uIq+lKZK+LOk1Sa9KukNSF0nDJD0naa6kuyR1Snk7p+25af8+OeeZmNJnSxq3M/fnoGhmBYs8l8ZIGgR8CRgZEQeTfR/+bOB7wDURsR+wAjg/HXI+sCKlX5PyIWlEOu4gYDxwvaTK5t6bg6KZFSYNtOSz5KED0FVSB6AbsAQYC9yb9t8KnJbWJ6Rt0v4TJSml3xkRmyJiPjAXGNXc23NQNLPC5V9V7CdpRs5yQcMpIhYD/wW8RRYMVwEvAisjoiZlWwQMSuuDgIXp2JqUv29u+naOKZgHWsysYAVMyamKiJHb2yGpN1ktbxiwEriHrPlbUjsMipKuo5FugYj4UlFKZGatWgB1dS0yJeckYH5EvAsg6VfAcUAvSR1SbXAwsDjlXwwMARal5nZPYHlOer3cYwrWWE1xRnNPamZlLICWmaf4FnC0pG7ABuBEsrjzR+AM4E7gXOD+lH9q2n427X8sIkLSVOCXkv4H2AsYDjzf3ELtMChGxK2525K6RcT65l7IzMpHS8xTjIjnJN0LzARqgJeAycDvgTslfTul3ZwOuRn4uaS5QDXZiDMR8Zqku4FZ6TwXRURtc8vVZJ+ipGNSYXYHhko6DLgwIr7Q3IuaWRvXQpO3I2ISMGmb5HlsZ/Q4IjYCH9/Bea4CrmqJMuUz+vxDYBxZ252I+DNwfEtc3Mzaovym47TV56PzGn2OiIXZdKAGza6amlkZKOPH/PIJigslHQuEpI7AJcDrxS2WmbVaAdEyo8+tUj7N588BF5FNhnwbODxtm1m7pTyXtqfJmmJEVAGf3AVlMbO2ooybz03WFCXtK+m3kt6VtEzS/ZL23RWFM7NWqiXeCNFK5dN8/iVwNzCQbGLkPcAdxSyUmbVi9ZO381naoHyCYreI+HlE1KTlF0CXYhfMzFqviPyWtqixZ5/7pNU/SLqc7JGbAM4CHtgFZTOz1qqMR58bG2h5kSwI1t/9hTn7AphYrEKZWeumNloLzEdjzz4P25UFMbM2og0PouQjrydaJB0MjCCnLzEibitWocysNWu7gyj5yOeFEJOAMWRB8QHgFOBpwEHRrL0q45piPqPPZ5C952xpRJwHHEb2ckcza6/q8lzaoHyazxsiok5SjaQewDK2fsutmbUnLfeS2VYpn6A4Q1Iv4GdkI9Jryd58a2btVLscfa6X8zLZGyU9CPSIiFeKWywza9XaY1CUdERj+yJiZnGKZGZWOo3VFP+7kX1B9sHqFvW3V7oxbq/DW/q0VkRdD1hZ6iJYASrea5n3Q7fL5nNEnLArC2JmbUTQbh/zMzPbvvZYUzQz25F22Xw2M9uhMg6K+bx5W5I+JekbaXuopL/7JquZtSPt/M3b1wPHAOek7TXAT4pWIjNr1RT5L21RPs3n0RFxhKSXACJihaRORS6XmbVm7Xz0ebOkSlJlWNIetNlHvc2sJbTVWmA+8mk+Xwv8Gugv6Sqy14Z9p6ilMrPWrYX6FCX1knSvpL9Kel3SMZL6SHpY0pz0s3fKK0nXSpor6ZXcp+4knZvyz5F07s7cWj7PPt8u6UWy14cJOC0iXt+Zi5pZG9ay/YU/Ah6MiDNSt1w34GvAoxFxdfo+1OXAV8ne5To8LaOBG4DR6XtSk4CRWel4UdLUiFjRnALlM/o8FFgP/BaYCqxLaWbWXrVATVFST+B44GaAiHgvIlYCE4BbU7ZbgdPS+gTgtshMB3pJGgiMAx6OiOoUCB8Gxjf31vLpU/w9Wz5g1QUYBswGDmruRc2sbVPLjCoMA94F/lfSYWSvJrwEGBARS1KepcCAtD4IWJhz/KKUtqP0ZmmyphgRh0TEoenncGAUfp+imeWnn6QZOcsFOfs6AEcAN0TEB4B1ZE3lBhGxy2c8FvxES0TMlDS6GIUxszYi/zBVFREjd7BvEbAoIp5L2/eSBcV3JA2MiCWpebws7V/M1m/9H5zSFpN9Ryo3/fG8S7iNfD5c9ZWczQqyyP52cy9oZm1cCw20RMRSSQslHRARs8kGc2el5Vzg6vTz/nTIVOBiSXeSDbSsSoFzGvCd+lFq4GR24rv0+dQUu+es15D1Md7X3AuaWRlouQbtF4Hb08jzPOA8ssrX3ZLOBxYAZ6a8DwCnAnPJBn/PA4iIaklXAi+kfFdERHVzC9RoUEyTtrtHxH809wJmVoZaKChGxMtkU2m2deJ28gZw0Q7OMwWY0hJlauxzBB0iokbScS1xITMrD6LFRp9bpcZqis+T9R++LGkqcA/Z6BAAEfGrIpfNzFqjNvyyh3zk06fYBVhO9k2W+vmKATgomrVX7TQo9k8jz6+yJRjWK+M/EjNrUhlHgMaCYiWwO1sHw3pl/EdiZk1pr83nJRFxxS4riZm1He00KJbvWyTNrPmi/Y4+/908ITMzoH3WFHdmRriZlbf22qdoZrZ9DopmZkkb/nxpPhwUzawgws1nM7OtOCiameVyUDQzy+GgaGaW+C05ZmbbcFA0M9uivT7mZ2a2XW4+m5nV8+RtM7NtOCiamWX8RIuZ2TZUV75R0UHRzArjPkUzs625+WxmlstB0cxsC9cUzcxylXFQrCh1AcysjUlf88tnyYekSkkvSfpd2h4m6TlJcyXdJalTSu+ctuem/fvknGNiSp8tadzO3J6DopkVpH6eYj5Lni4BXs/Z/h5wTUTsB6wAzk/p5wMrUvo1KR+SRgBnAwcB44HrJVU29/4cFM2scBH5LU2QNBj4R+CmtC1gLHBvynIrcFpan5C2SftPTPknAHdGxKaImA/MBUY199YcFM2sYAXUFPtJmpGzXLDNqX4IXAbUN7b7AisjoiZtLwIGpfVBwEKAtH9Vyt+Qvp1jCuaBlp00+H0b+dqNCxq29xz6Hj//wZ48cm9vvnbjAgYMfo93FnXiqgv3Zu2qDhx6zFq++b/zWbqwEwB/eqAnt1+zZ6mK327022M9l06cQe/eGwngwd8N4/77hrN79/eY+I3n6L/nOpYt3Y3vfms0a9d24p/Pms2Yk7Lfs8rKYMjQ1Zxz+j+xdk0njjxqKRde/GcqKoNpvx/GPXccUNqb29UKm7xdFREjt7dD0keAZRHxoqQxLVO4nVe0oChpClB/0wcX6zqltuiNLnzhH7JfioqK4PaZs/jTH3py5sXLeOnp3bn7xwM48+J3OOviZdx81V4AvPrcbnzj3H1LWex2p7ZW3HTDIbwxpzddu27m2p8+xswZA/iH8Qt4eWZ/7rnjAD5+zmw+/onZ/O/kQ7jvrgO4767s73XUMW9z+hlzWbumExUVwRcueZmv/+cHqXq3Gz+88TGmPzOQhQt6lPgOd60Wep/iccBHJZ0KdAF6AD8CeknqkGqDg4HFKf9iYAiwSFIHoCewPCe9Xu4xBStm8/kWsk7PduPwD61lyYJOLFvciWPGreaRu/sA8MjdfThm/OoSl659W1HdlTfm9AZgw4aOvPVWd/r128DRx77NI9OGAvDItKEcc9zbf3fsmBMX8fhj2e/c/u+v5u23d2Ppkt2pqangyccGb/eYctcSo88RMTEiBkfEPmQDJY9FxCeBPwJnpGznAven9alpm7T/sYiIlH52Gp0eBgwHnm/uvRUtKEbEk0B1sc7fGo2ZsILHf5P94vXut5nqZR0BqF7Wgd79NjfkO/DI9dzw8Gy+/Yt57L3/xpKUtT3rP2Ad79tvJX99vQ+9+mxiRXVXAFZUd6FXn01b5e3cuYYjj1rKn57Muqj69ttA1bJuDfur3u1K334bdl3hW4OgxQZaduCrwFckzSXrM7w5pd8M9E3pXwEuB4iI14C7gVnAg8BFEVHb3IuXvE8xdbxeANCFbk3kbr06dKzj6JNXM+U7A7ezV0QIgLl/6cq/jDqQjesrOWrsaiZNmc+nP3jgri1sO9alSw1fv2I6k39yGBvWd9xmr/7u93j0sUuY9Wpf1q7ptMvK2Ba09BMtEfE48Hhan8d2Ro8jYiPw8R0cfxVwVUuUpeSjzxExOSJGRsTIjnQudXGa7aixa5j7l66srMp+0VZUdaRP/6x22Kf/ZlYuz/7/Wb+2ko3rsylULzzWg8qOQY8+Nds/qbWoyso6vn7Fszz+yBCeeSqr+a2s7kzvPllNr3efDaxasfW/weNPWMQTj23prlpe1ZV+/dc3bPfbYwPLq7rugtK3MpHn0gaVPCiWizGnrWxoOgNMf6gHJ52Z9R6cdGY1z07LOuJ777GZ+n8tBxy+nooKWF3d7Hmmlrfg3y97kYULevDre/ZvSJ3+zEBOGvcWACeNe4vpz+zVsK/bbps55LB3efZPW9L+9tfe7DVoLQP2XEeHDnUcP3bRVse0B0WYvN2qlLz5XA46d63liA+t4UeXDW5Iu+vH/fn6jQsYf3Y1yxZnU3IAPvSRVXzkX6uorRGbNlbw3c/vTfbPzIppxMHLOfHkt5j/Rg+u+9kjANx600Hcc8cBTJz0HCefOp9l73Tju986uuGYYz+4mJkzBrBp45Zfk7q6Cm649nC+/f2nqagIHvrDPrz1ZvsaeSairF8yq2h+Z2jjJ5buAMYA/YB3gEkRcXNjx/RQnxitE4tSHiuOygP2K3URrADPvnkLqzYs2an/hbv3GhwfOP6SvPI+9dvLXtzRPMXWqmg1xYg4p1jnNrPSaqtN43y4+WxmhQmgjJvPDopmVrjyjYkOimZWODefzcxylPPos4OimRWmDU/MzoeDopkVJJu8Xb5R0UHRzArXMq8Oa5UcFM2sYK4pmpnVc5+imVmu8n722UHRzArn5rOZWRIt9o2WVslB0cwK55qimVmO8o2JDopmVjjVlW/72UHRzAoTePK2mVk9EZ68bWa2FQdFM7McDopmZon7FM3MtubRZzOzBlHWzeeKUhfAzNqYIAuK+SyNkDRE0h8lzZL0mqRLUnofSQ9LmpN+9k7pknStpLmSXpF0RM65zk3550g6d2duz0HRzApXl+fSuBrg0ogYARwNXCRpBHA58GhEDAceTdsApwDD03IBcANkQRSYBIwGRgGT6gNpczgomlnBFJHX0piIWBIRM9P6GuB1YBAwAbg1ZbsVOC2tTwBui8x0oJekgcA44OGIqI6IFcDDwPjm3pv7FM2scPn3KfaTNCNne3JETN42k6R9gA8AzwEDImJJ2rUUGJDWBwELcw5blNJ2lN4sDopmVpgIqM179LkqIkY2lkHS7sB9wL9HxGpJOZeKkHbtV6bdfDazwrXAQAuApI5kAfH2iPhVSn4nNYtJP5el9MXAkJzDB6e0HaU3i4OimRWuZUafBdwMvB4R/5OzaypQP4J8LnB/Tvq/plHoo4FVqZk9DThZUu80wHJySmsWN5/NrDABtMw3Wo4D/gX4i6SXU9rXgKuBuyWdDywAzkz7HgBOBeYC64HzACKiWtKVwAsp3xURUd3cQjkomlmBAmLnn2iJiKcB7WD3idvJH8BFOzjXFGDKThcKB0UzK1RQyEBLm+OgaGaFK+PH/BwUzaxwDopmZvXK+4UQDopmVpgA/OowM7McrimamdUr6DG/NsdB0cwKExAtME+xtXJQNLPCtcwTLa2Sg6KZFc59imZmSYRHn83MtuKaoplZvSBqa0tdiKJxUDSzwrTcq8NaJQdFMyucp+SYmWUCCNcUzcySaJmXzLZWDopmVrByHmhRtKKhdUnvkn2Todz0A6pKXQgrSLn+ne0dEXvszAkkPUj255OPqoho9ofpS6FVBcVyJWlGU9++tdbFf2ftlz9xamaWw0HRzCyHg+KuMbnUBbCC+e+snXKfoplZDtcUzcxyOCiameVwUCwiSeMlzZY0V9LlpS6PNU3SFEnLJL1a6rJYaTgoFomkSuAnwCnACOAcSSNKWyrLwy1Am5psbC3LQbF4RgFzI2JeRLwH3AlMKHGZrAkR8SRQXepyWOk4KBbPIGBhzvailGZmrZiDoplZDgfF4lkMDMnZHpzSzKwVc1AsnheA4ZKGSeoEnA1MLXGZzKwJDopFEhE1wMXANOB14O6IeK20pbKmSLoDeBY4QNIiSeeXuky2a/kxPzOzHK4pmpnlcFA0M8vhoGhmlsNB0cwsh4OimVkOB8U2RFKtpJclvSrpHkndduJct0g6I63f1NjLKiSNkXRsM67xpqS/++rbjtK3ybO2wGt9U9J/FFpGs205KLYtGyLi8Ig4GHgP+FzuTknN+o53RHwmImY1kmUMUHBQNGuLHBTbrqeA/VIt7ilJU4FZkiol/UDSC5JekXQhgDI/Tu93fAToX38iSY9LGpnWx0uaKenPkh6VtA9Z8P1yqqV+SNIeku5L13hB0nHp2L6SHpL0mqSbADV1E5J+I+nFdMwF2+y7JqU/KmmPlPY+SQ+mY56S9P6W+MM0q9esmoWVVqoRngI8mJKOAA6OiPkpsKyKiKMkdQb+JOkh4APAAWTvdhwAzAKmbHPePYCfAcenc/WJiGpJNwJrI+K/Ur5fAtdExNOShpI9tXMgMAl4OiKukPSPQD5Pg3w6XaMr8IKk+yJiObAbMCMivizpG+ncF5N9UOpzETFH0mjgemBsM/4YzbbLQbFt6Srp5bT+FHAzWbP2+YiYn9JPBg6t7y8EegLDgeOBOyKiFnhb0mPbOf/RwJP154qIHb1X8CRghNRQEewhafd0jY+lY38vaUUe9/QlSaen9SGprMuBOuCulP4L4FfpGscC9+Rcu3Me1zDLm4Ni27IhIg7PTUjBYV1uEvDFiJi2Tb5TW7AcFcDREbFxO2XJm6QxZAH2mIhYL+lxoMsOske67spt/wzMWpL7FMvPNODzkjoCSNpf0m7Ak8BZqc9xIHDCdo6dDhwvaVg6tk9KXxAjezQAAADRSURBVAN0z8n3EPDF+g1J9UHqSeATKe0UoHcTZe0JrEgB8f1kNdV6FUB9bfcTZM3y1cB8SR9P15Ckw5q4hllBHBTLz01k/YUz08eXfkrWIvg1MCftu43sTTBbiYh3gQvImqp/Zkvz9bfA6fUDLcCXgJFpIGcWW0bBv0UWVF8ja0a/1URZHwQ6SHoduJosKNdbB4xK9zAWuCKlfxI4P5XvNfyJB2thfkuOmVkO1xTNzHI4KJqZ5XBQNDPL4aBoZpbDQdHMLIeDoplZDgdFM7Mc/wcDuqpHXpjvqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(model_over, X_test, y_test)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1kkgQYEkqej",
        "outputId": "388febd2-e481-4193-de92-adfb6c8786ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(38079, 46)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlsRdfZcCduI"
      },
      "source": [
        "Train Logistic Regression with Standerdisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAK1YfuACduI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djQNgzt3CduJ",
        "outputId": "480030a2-2179-4e98-ee15-3c21fa81e0b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 32660, 1: 32660})\n"
          ]
        }
      ],
      "source": [
        "oversample = SMOTE()\n",
        "X_train_smote_scaled, y_train_smote_scaled = oversample.fit_resample(X_train_scaled, y_train)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y_train_smote_scaled)\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiIMYJsLCduK",
        "outputId": "348c404d-6349-492a-b846-92d2f6b47e0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8546065259117083"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_smote_scaled = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_smote_scaled.fit(X_train_smote_scaled, y_train_smote_scaled)\n",
        "model_smote_scaled.score(X_test_scaled, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYrN8RhbCduK"
      },
      "outputs": [],
      "source": [
        "predicted_smote_scaled = model_smote_scaled.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'model_lr_lbfgs_standardised.sav'\n",
        "pickle.dump(model_smote_scaled, open(f\"/content/drive/My Drive/BT4222/{filename}\", 'wb'))"
      ],
      "metadata": {
        "id": "e1dHOnlMlD32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXWDoiZyCduK",
        "outputId": "279a68c5-2309-467a-d58b-cdb80087f546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8546065259117083\n",
            "Precision: 0.5053619302949062\n",
            "Recall: 0.8151351351351351\n",
            "F1-score: 0.6239139429044269\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted_smote_scaled)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted_smote_scaled)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted_smote_scaled)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted_smote_scaled)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "XuZhXT9ICduL",
        "outputId": "c73c1a1a-6edf-4b72-a9f8-8cb167190bc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f368cef0390>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_confusion_matrix(model_smote_scaled, X_test_scaled, y_test) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "pxAL55jiNGxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oversample = SMOTE()\n",
        "X_train_smote_scaled, y_train_smote_scaled = oversample.fit_resample(X_train_scaled, y_train)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y_train_smote_scaled)\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUaJn-hXNWy_",
        "outputId": "aaaca8b5-3bed-4dca-d3ee-5435c4eebf72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 32660, 1: 32660})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_smote_scaled = LogisticRegression(max_iter=10000, random_state=42)\n",
        "model_smote_scaled.fit(X_train_smote_scaled, y_train_smote_scaled)\n",
        "model_smote_scaled.score(X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5ROWwa9NZ22",
        "outputId": "c55f5edc-dc0d-4029-93e9-56dbcc900da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8527404563872893"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEdA6YskNckP"
      },
      "outputs": [],
      "source": [
        "predicted_smote_scaled = model_smote_scaled.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'model_lr_lbfgs_standardised.sav'\n",
        "pickle.dump(model_smote_scaled, open(f\"/content/drive/My Drive/BT4222/{filename}\", 'wb'))"
      ],
      "metadata": {
        "id": "DAILUe5ENckR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782331d5-469f-47cc-adfd-183c8432db75",
        "id": "TG3u8UnSNckR"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8527404563872893\n",
            "Precision: 0.5014557670772677\n",
            "Recall: 0.8068468468468468\n",
            "F1-score: 0.6185082872928177\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_test, predicted_smote_scaled)}\")\n",
        "print(f\"Precision: {precision_score(y_test, predicted_smote_scaled)}\")\n",
        "print(f\"Recall: {recall_score(y_test, predicted_smote_scaled)}\")\n",
        "print(f\"F1-score: {f1_score(y_test, predicted_smote_scaled)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "2a6392d9-69e2-4c82-c3ce-39b11eaa3053",
        "id": "joT7pn26NckS"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f1a1225ca90>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUUAAAEGCAYAAADyuIefAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwV1Z338c+3m1VkaWjEBYioqIO7EtE442PUADqZoPO4JyMxJo5L1BgzLpMZiSZONDpjNIk6RFDMGNdoJM8YkLgEVxTcoizagrKIC4uggAjdv+ePOt1cCN19b9OX7r79fb9e9aLq1KmqU90vfn1OnVN1FBGYmVmmrKULYGbWmjgompnlcFA0M8vhoGhmlsNB0cwsR4eWLkCuyt7lsfOAji1dDCvAW29WtHQRrABr1q3g8/WrtSXnGPHlbrF0WXVeeWe8tnZyRIzckuttba0qKO48oCMvTB7Q0sWwAhz7lZNbughWgOeqxm3xOZYuq+aFyQPzylu+w1uVW3zBraxVBUUza/0CqKGmpYtRNA6KZlaQIFgX+TWf2yIHRTMrmGuKZmZJEFSX8OvBDopmVrAaHBTNzICso6XaQdHMbAPXFM3MkgDW+ZmimVkmCDefzczqBFSXbkx0UDSzwmRvtJQuB0UzK5CoZou+KdGqOSiaWUGyjhYHRTMzoHacooOimVmdGtcUzcwyrimameUIRHUJz2TioGhmBXPz2cwsCcTnUd7SxSgaB0UzK0g2eNvNZzOzOu5oMTNLIkR1uKZoZlanxjVFM7NM1tFSuqGjdOvAZlYUtR0t+SyNkTRe0oeSXs9Ju07SbEmvSXpIUq+cfZdLqpI0R9KInPSRKa1K0mU56YMkTUvp90rq1FiZHBTNrGDVobyWPNwBjNwkbQqwd0TsC7wJXA4gaQhwCrBXOuZmSeWSyoFfAccAQ4BTU16Aa4EbImI3YDlwZmMFclA0s4LUvtGSz9LouSKmAss2SXs0ItanzeeB/ml9FHBPRKyNiHlAFXBwWqoiYm5EfA7cA4ySJOBI4IF0/ATguMbKVLoPBsysaGry732ulDQ9Z3tsRIwt4FLfAu5N6zuRBclaC1MawIJN0ocBfYCPcwJsbv56OSiaWUGyD0LkHRSXRMTQplxH0g+B9cBdTTm+qRwUzawggVhX5Nf8JH0T+CpwVETd1IGLgAE52fqnNOpJXwr0ktQh1RZz89fLzxTNrCARUB1leS1NIWkkcAnwtYhYnbNrInCKpM6SBgGDgReAF4HBqae5E1lnzMQUTJ8ATkjHjwYebuz6rimaWYHUbIO3Jd0NHEH27HEhMIast7kzMCXrK+H5iDg7It6QdB8wk6xZfV5EVKfzfBeYDJQD4yPijXSJS4F7JP0EeBkY11iZHBTNrCABzfaaX0ScupnkegNXRFwNXL2Z9EeARzaTPpesdzpvDopmVjB/ZNbMLAnkj8yamdXKpjgt3dBRundmZkUif0/RzKxWUNAbLW2Og6KZFcw1RTOzJEKuKZqZ1co6Wjybn5lZ4jlazMzqZB0tfqZoZlbHb7SYmSV+o8XMbBP5TErVVjkomllBImBdjYOimRlQ23x2UDQzq+M3Woz/vGgA0/7Ug16V6xn7xBwAJvxse56b3BMJelWu4wc/n0+f7ddz/819efzB3gBUV8OCt7pw719ep0dFNacfPISu21ZTVgblHYJfTnoTgN9cvz1//G1vevauBuCMy9/j4KM+aZmbLUGVfVdz8SXTqKhYSwRMemQXHn5od771nVcZdsh7rF9fxuL3tuWG67/IqlWdOODA9/nmmX+hY8ca1q0rY/yv9+XVV/oB0KFDNed892X23e9DamrEnbfvwzNP92+kBKXDQ3K2QJpr4UayT4TfFhHXFPN6xTT85GV87YwlXHfhwLq0E875kNGXvA/A72+r5H9u2J4Lr13Iied+xInnfgTA84/24MFf96VHRXXdcT+7v4qefarZ1PHf+YgTz/moyHfSPlVXi9v+e3/erqqga9d13HTzFF6a0Y+XX+rHHeP2oaamjDO+/SonnTqL22/bjxUrOnPlFX/LsqVd+cLOK/jxT6dy+qn/AMDJp81ixced+c4ZxyIF3bt/3sJ3t7WVdvO5aHcmqRz4FXAMMAQ4VdKQYl2v2PY5ZBXdKzYOZN2619Stf7amDG3mj+cTv6/giOOWF7t41ojly7rydlUFAGvWdGT+/B5UVq7h5RnbU5M6DWbP6kNl5RoA5r5dwbKlXQF4950edO5UTYeO2e9/+Ih53HvP3wDZe8ArV3be2rfT4mrSPC2NLW1RMWuKBwNVaY4EJN0DjCKbdKZk3H7N9vzp/t5061HNzx6o2mjfZ6vF9Ce7c97VCzckKvjXU3cFwd//01KO/cbSul1/uL0vjz3Qm8H7ruasMe/Rvddf1yZty23XbxW77vYxs2f32Sh9+Ih5TP3zwL/Kf9jfLaSqqhfr15XTrVtWKzx99Ovss9+HLF68Lbf84kA+/rjLVil7a5D1Ppfuu8/FrAPvBCzI2V6Y0jYi6SxJ0yVN/2hp2wsCZ1z2PnfNmMmR/7icieP7brTv+Sk92Wvoqo2azv/1+yp+9eibXH3XXCbeUclfnu8GwFdHL+H252Zy85Q59O63jrFX7rhV76O96NJlHT+84lnG3rI/a1Z3rEs/+bSZVFeX8cRjGwfFgV9Ywbe+/Rq/+Hk2n3t5edB3uzXMnNmHC84dzuyZffj2P7+6Ve+hpdUO3s5naYta/MFARIyNiKERMbRvn7b71+fI45fz9CM9N0r788O9/qrpXLnDOgB6Va7nsJErmP3yNgBU9F1PeTmUlcExX1/GnFe22ToFb0fKy2v44ZhnefLxgTyb0zFy9PB5HDxsMdddMwxymnx9Klfz7z96hv/82TDeX7wtACtXduKzNeV1xz81dQC77tb+Ho+UcvO5mEFxETAgZ7t/SisZi+Z2qlt/bnJPBuy2tm571coyXnt+W740cmVd2mery1j9aVnd+ow/d2fnPT8DYOkHG55kPPvHnuy8x2fFLn47E3zv4hdZML8HD/1uj7rUg4Yu5oST5nDlFYexdu2G30G3bp9z5U+e4vZx+zLzjcqc84hpz+/Ivvt9CMD+B3zA/Pk9ttZNtAq1vc+lWlMs5jPFF4HBkgaRBcNTgNOKeL2i+uk5X+C157ZlxbIOfP2gIfzTxe/zwuM9WPh2Z8rKYLudPueCazc8O3zmj7046PBP6LLNhs6Y5R914MozBwFQvR6+fPzHfPHL2bCbcT/Zkbff6IoE/fp/zgU/W4A1nyF7LeGor7zLvLk9+cWtjwIwYfw+nH3uy3TsWM3V104FYM6s3vzyxqH8w6gqdtzxU079xkxO/Ub2GPzfLjucFR934fbb9uUHl07jrHNeYcWKztxw3Rdb7L5aSin3Pisiindy6Vjg52RDcsaniazrNXS/LvHC5AENZbFW5tivnNzSRbACPFc1jhVrFm9RFa5iz+3iyPEn5JX3wcNumRERQ+vbL2k88FXgw4jYO6X1Bu4FdgbeAU6KiOWSRDbE71hgNfDNiHgpHTMa+Ld02p9ExISUfhBwB9AVeAS4MBoJekUN9xHxSETsHhG7NhYQzaztaMbm8x3AyE3SLgMei4jBwGNpG7LhfYPTchZwC9QF0THAMLJRL2MkVaRjbgG+k3Pcptf6K6VbBzazomjOZ4oRMRVYtknyKGBCWp8AHJeTfmdkngd6SdoBGAFMiYhlEbEcmAKMTPt6RMTzqXZ4Z8656uXX/MysYAV0olRKmp6zPTYixjZyTL+IWJzW3wf6pfX6hvk1lL5wM+kNclA0s4IU+JHZJQ09U2z0WhEhqXgdH5vh5rOZFazI4xQ/SE1f0r8fpvT6hvk1lN5/M+kNclA0s4JEwPqasryWJpoIjE7ro4GHc9JPV+YQYEVqZk8GhkuqSB0sw4HJad9KSYeknuvTc85VLzefzaxgzTUwW9LdwBFkzx4XkvUiXwPcJ+lM4F3gpJT9EbLhOFVkQ3LOAIiIZZJ+TDY2GuCqiKjtvDmXDUNy/piWBjkomllBmnPiqog4tZ5dR20mbwDn1XOe8cD4zaRPB/YupEwOimZWsGijr/Dlw0HRzArWVj/2kA8HRTMrSISnIzAzyyGqPcWpmdkGfqZoZpZ4Nj8zs1yRPVcsVQ6KZlYw9z6bmSXhjhYzs425+WxmlsO9z2ZmSYSDopnZRjwkx8wsh58pmpklgahx77OZ2QYlXFF0UDSzArmjxcxsEyVcVXRQNLOCtcuaoqRf0MDfg4i4oCglMrNWLYCamnYYFIHpW60UZtZ2BNAea4oRMSF3W9I2EbG6+EUys9aulMcpNjrYSNKhkmYCs9P2fpJuLnrJzKz1ijyXNiifEZg/B0YASwEi4lXg8GIWysxaMxGR39IW5TUsPSIWbJJUXYSymFlb0Uw1RUkXSXpD0uuS7pbURdIgSdMkVUm6V1KnlLdz2q5K+3fOOc/lKX2OpBFbcmv5BMUFkr4EhKSOkn4AzNqSi5pZGxYQNcpraYiknYALgKERsTdQDpwCXAvcEBG7AcuBM9MhZwLLU/oNKR+ShqTj9gJGAjdLKm/q7eUTFM8GzgN2At4D9k/bZtZuKc+lUR2ArpI6ANsAi4EjgQfS/gnAcWl9VNom7T9KklL6PRGxNiLmAVXAwU29s0YHb0fEEuDrTb2AmZWg/DtRKiXlDu8bGxFjASJikaTrgfnAGuBRYAbwcUSsT/kXklXISP8uSMeul7QC6JPSn8+5Ru4xBWs0KEraBbgROITsR/EccFFEzG3qRc2sjcs/KC6JiKGb2yGpgqyWNwj4GLifrPnbovJpPv8WuA/YAdiRrOB3F7NQZtaK1Q7ezmdp2NHAvIj4KCLWAQ8ChwG9UnMaoD+wKK0vAgYApP09yUbF1KVv5piC5RMUt4mI30TE+rT8D9ClqRc0s7YvIr+lEfOBQyRtk54NHgXMBJ4ATkh5RgMPp/WJaZu0//GIiJR+SuqdHgQMBl5o6r019O5z77T6R0mXAfeQ/Y04GXikqRc0sxLQDO8+R8Q0SQ8ALwHrgZeBscD/AvdI+klKG5cOGQf8RlIVsIysx5mIeEPSfWQBdT1wXkQ0edhgQ88UZ5AFwdq7/+fc+wEub+pFzaxtUzO9rRIRY4AxmyTPZTO9xxHxGXBiPee5Gri6OcrU0LvPg5rjAmZWYtrwK3z5yOt7ipL2BoaQ8ywxIu4sVqHMrDXLqxOlzcpnSM4Y4AiyoPgIcAzwNOCgaNZelXBNMZ/e5xPIeoXej4gzgP3IusLNrL2qyXNpg/JpPq+JiBpJ6yX1AD5k4zFBZtaetNePzOaYLqkX8GuyHulPyd5qMbN2qrl6n1ujfN59Pjet3ippEtAjIl4rbrHMrFVrj0FR0oEN7YuIl4pTJDOzltNQTfE/G9gXZJ/3aVZvvrYNI3bcv7lPa0VUvldLl8BaQrtsPkfEl7dmQcysjQia5TW/1iqvwdtmZhtpjzVFM7P6tMvms5lZvUo4KOYz77MkfUPSFWl7oKQmz39gZiWgnc/7fDNwKHBq2v4E+FXRSmRmrZoi/6Utyqf5PCwiDpT0MkBELK+dh9XM2ql23vu8Ls2hGgCS+tJmX/U2s+bQVmuB+cin+XwT8BCwnaSryT4b9h9FLZWZtW4l/Ewxn3ef75I0g+zzYQKOi4hZRS+ZmbVObfh5YT7y+cjsQGA18IfctIiYX8yCmVkr1p6DItnMWrUTWHUhm7h6DuC3Xs3aKZVwr0I+zed9crfT13POrSe7mVmbVvAbLRHxkqRhxSiMmbUR7bn5LOn7OZtlwIHAe0UrkZm1biXe0ZLPkJzuOUtnsmeMo4pZKDNr5ZppSI6kXpIekDRb0ixJh0rqLWmKpLfSvxUpryTdJKlK0mu5H8KWNDrlf0vS6C25tQZrimnQdveI+MGWXMTMSkzz1RRvBCZFxAnpTbltgH8FHouIayRdBlwGXEo2vfLgtAwDbgGGSeoNjAGGppLNkDQxIpY3pUD11hQldYiIauCwppzYzEqTyHqf81kaPI/UEzgcGAcQEZ9HxMdkLdEJKdsE4Li0Pgq4MzLPA70k7QCMAKZExLIUCKcAI5t6fw3VFF8ge374iqSJwP3AqtqdEfFgUy9qZm1YYc8UKyVNz9keGxFj0/og4CPgdkn7kc0WeiHQLyIWpzzvA/3S+k7AgpxzLUxp9aU3ST69z12ApWRzstSOVwzAQdGsvco/KC6JiKH17OtAVvE6PyKmSbqRrKm84TIRIW3dbp2GguJ2qef5dTYEw1ol3PdkZo1qngiwEFgYEdPS9gNkQfEDSTtExOLUPP4w7V8EDMg5vn9KWwQcsUn6k00tVEO9z+XAtmnpnrNeu5hZO9Uc31OMiPeBBZL2SElHATOBiUBtD/Jo4OG0PhE4PfVCHwKsSM3sycBwSRWpp3p4SmuShmqKiyPiqqae2MxKWPO1Fc8H7ko9z3OBM8gqa/dJOhN4Fzgp5X0EOBaoIvsewxkAEbFM0o+BF1O+qyJiWVML1FBQLN2vSJpZ00XzvfscEa+QDaXZ1FGbyRvAefWcZzwwvjnK1FBQ/KtCmZkBJd2rUG9Q3JLqp5mVtlJ+zc9TnJpZ4RwUzcySNjzVQD4cFM2sIMLNZzOzjTgompnlclA0M8vhoGhmlpT4l7cdFM2scA6KZmYbtOspTs3MNuXms5lZLQ/eNjPbhIOimVnGb7SYmW1CNaUbFR0UzawwfqZoZrYxN5/NzHI5KJqZbeCaoplZLgdFM7OkGWfza40cFM2sIB6naGa2qSjdqFjW0gUws7ZHkd+S17mkckkvS/p/aXuQpGmSqiTdK6lTSu+ctqvS/p1zznF5Sp8jacSW3Jtris1gwrSZrPm0nJoaqF4vzj9md07/l8UcOmIlEfDxkg5c/72BLPugIwD7HvopZ1+1iA4dghXLOvAv/3e3Fr6D0lfZdzUXXzKNioq1RMCkR3bh4Yd251vfeZVhh7zH+vVlLH5vW264/ousWtWJ3fdYyvkXzQBABHf9Zi+ee6Y/AKOOf5MRx8xF2nCedqX5B29fCMwCeqTta4EbIuIeSbcCZwK3pH+XR8Rukk5J+U6WNAQ4BdgL2BH4k6TdI6K6KYUpWlCUNB74KvBhROxdrOu0FpecuCsrl234cT5wy3bced0OAIw68yO+cdEH3HRZf7r1qOa7P13ID7++Cx8t6kTPPutaqsjtSnW1uO2/9+ftqgq6dl3HTTdP4aUZ/Xj5pX7cMW4famrKOOPbr3LSqbO4/bb9ePednlx47tHU1JRR0XsNv7r1UaY9tyMDBn7CiGPmctH5R7NuXRk//ulUXpi2A4vf697St7hVNVdHi6T+wN8DVwPflyTgSOC0lGUC8COyoDgqrQM8APwy5R8F3BMRa4F5kqqAg4HnmlKmYjaf7wBGFvH8rdrqT8vr1rt0ral7BPPl45fzzCM9+WhRJwBWLO3YEsVrd5Yv68rbVRUArFnTkfnze1BZuYaXZ2xPTU3232D2rD5UVq4BYO3aDnXpnTpV11WMBgxcyZzZfer2v/5aXw7720Vb/X5ammryW4BKSdNzlrM2OdXPgUuA2jDbB/g4Itan7YXATml9J2ABQNq/IuWvS9/MMQUrWk0xIqbmtvlLWoj/uHsuBPzvb/rwx7v6APDNSxdz9InLWbWynEtO2BWA/ruspbxj8LMHqthm2xp+f1slf3qgd0uWvt3Zrt8qdt3tY2bP7rNR+vAR85j654F123vsuZTvXfwi2/VbzfXXHkxNTRnvvtOT0Wf8he7d1/L55+UMPfh93nqzYmvfQssKCuloWRIRQze3Q1JtS3KGpCOaqXRbrMWfKaa/HGcBdGGbFi5N03z/uN1Y+n5HevZZxzX3zGVBVWden7Ytd1y7A3dcuwMnf/cDvvatJfzm+u0p7xAM3mcNl560C527Bj+f+BazXurGormdW/o22oUuXdbxwyueZewt+7Nm9YZa+smnzaS6uownHtsQFOfM7sM53xnJgIEr+f6/vMD0F3Zgwfwe3H/vnvzkmqms/aycuW/3oqZGLXErLaqZhuQcBnxN0rFAF7JnijcCvSR1SLXB/kBtVXwRMABYKKkD0BNYmpNeK/eYgrV473NEjI2IoRExtCNtMzAsfT/7z7ViaUeemdSTPQ9YvdH+xx+q4G+PXQHAR4s7MuPP3Vm7ppyVyzrwl2nbssuQNVu9zO1ReXkNPxzzLE8+PpBnn+5fl3708HkcPGwx110zjGwU3sYWzO/BZ2s6sPOg7Hf46KRduPC8r3DJxUfy6acdWbSwfT1PBDZ0tjS2NHSKiMsjon9E7EzWUfJ4RHwdeAI4IWUbDTyc1iembdL+xyMiUvopqXd6EDAYeKGpt9biQbGt69y1mq7dquvWD/o/n/DO7C7sOGhtXZ5DR6xgQVUW8J+b1JO9vriKsvKgc9ca9jxgNfPfapt/DNqW4HsXv8iC+T146Hd71KUeNHQxJ5w0hyuvOIy1azc0nPpt/yllZdljru22W0X/gSv54P1uAPTs9RkAffuu4kuHLeLJxwfSntQO3m6uITmbcSlZp0sV2TPDcSl9HNAnpX8fuAwgIt4A7gNmApOA85ra8wytoPnc1lX0Xc+Yce8AUN4heOKhCqY/2YN///U79N91LTU18OGiTtx0aVYzWVDVhelPdufWx+YQNWLSb3vz7pyuLXgH7cOQvZZw1FfeZd7cnvzi1kcBmDB+H84+92U6dqzm6munAjBnVm9+eeNQ9tp7CSeePJv11WVEDdx800GsXJn98frhFc/So8fnrF8vbv7lgaxa1anF7qtFRDT7R2Yj4kngybQ+l6z3eNM8nwEn1nP81WQ92FtMUaSR6ZLuBo4AKoEPgDERMa6hY3qodwzTUUUpjxVH+V57NJ7JWo3nqsaxYs3iLXoI2r1X/zjg8AvzyvvUHy6ZUV9HS2tVzN7nU4t1bjNrWX732cysVgCeo8XMLEfpxkQHRTMrnJvPZmY5PMWpmVktT3FqZrZBNni7dKOig6KZFc5ztJiZbeCaoplZLT9TNDPL1fzvPrcmDopmVjg3n83Mkmi+OVpaIwdFMyuca4pmZjlKNyY6KJpZ4VRTuu1nB0UzK0zgwdtmZrVEePC2mdlGHBTNzHI4KJqZJX6maGa2Mfc+m5nViZJuPpe1dAHMrI0JsqCYz9IASQMkPSFppqQ3JF2Y0ntLmiLprfRvRUqXpJskVUl6TdKBOecanfK/JWn0ltyeg6KZFa4mz6Vh64GLI2IIcAhwnqQhwGXAYxExGHgsbQMcAwxOy1nALZAFUWAMMAw4GBhTG0ibwkHRzAqmiLyWhkTE4oh4Ka1/AswCdgJGARNStgnAcWl9FHBnZJ4HeknaARgBTImIZRGxHJgCjGzqvfmZopkVLv9nipWSpudsj42IsZtmkrQzcAAwDegXEYvTrveBfml9J2BBzmELU1p96U3ioGhmhYmA6rx7n5dExNCGMkjaFvgd8L2IWCkp51IR0tadZdrNZzMrXDN0tABI6kgWEO+KiAdT8gepWUz698OUvggYkHN4/5RWX3qTOCiaWeGap/dZwDhgVkT8V86uiUBtD/Jo4OGc9NNTL/QhwIrUzJ4MDJdUkTpYhqe0JnHz2cwKE0DzzNFyGPBPwF8kvZLS/hW4BrhP0pnAu8BJad8jwLFAFbAaOAMgIpZJ+jHwYsp3VUQsa2qhHBTNrEABseVvtETE04Dq2X3UZvIHcF495xoPjN/iQuGgaGaFCgrpaGlzHBTNrHAl/Jqfg6KZFc5B0cysVml/EMJB0cwKE4A/HWZmlsM1RTOzWgW95tfmOCiaWWECohnGKbZWDopmVrjmeaOlVXJQNLPC+ZmimVkS4d5nM7ONuKZoZlYriOrqli5E0Tgomllhmu/TYa2Sg6KZFc5DcszMMgGEa4pmZkk0z0dmWysHRTMrWCl3tChaUde6pI/I5mQoNZXAkpYuhBWkVH9nX4iIvltyAkmTyH4++VgSEU2emL4ltKqgWKokTW9s7ltrXfw7a788xamZWQ4HRTOzHA6KW8fYli6AFcy/s3bKzxTNzHK4pmhmlsNB0cwsh4NiEUkaKWmOpCpJl7V0eaxxksZL+lDS6y1dFmsZDopFIqkc+BVwDDAEOFXSkJYtleXhDqBNDTa25uWgWDwHA1URMTciPgfuAUa1cJmsERExFVjW0uWwluOgWDw7AQtythemNDNrxRwUzcxyOCgWzyJgQM52/5RmZq2Yg2LxvAgMljRIUifgFGBiC5fJzBrhoFgkEbEe+C4wGZgF3BcRb7Rsqawxku4GngP2kLRQ0pktXSbbuvyan5lZDtcUzcxyOCiameVwUDQzy+GgaGaWw0HRzCyHg2IbIqla0iuSXpd0v6RttuBcd0g6Ia3f1tDHKiQdIelLTbjGO5L+ata3+tI3yfNpgdf6kaQfFFpGs005KLYtayJi/4jYG/gcODt3p6QmzeMdEd+OiJkNZDkCKDgomrVFDopt11PAbqkW95SkicBMSeWSrpP0oqTXJP0zgDK/TN93/BOwXe2JJD0paWhaHynpJUmvSnpM0s5kwfeiVEv9O0l9Jf0uXeNFSYelY/tIelTSG5JuA9TYTUj6vaQZ6ZizNtl3Q0p/TFLflLarpEnpmKck7dkcP0yzWk2qWVjLSjXCY4BJKelAYO+ImJcCy4qI+KKkzsAzkh4FDgD2IPu2Yz9gJjB+k/P2BX4NHJ7O1Tsilkm6Ffg0Iq5P+X4L3BART0saSPbWzt8AY4CnI+IqSX8P5PM2yLfSNboCL0r6XUQsBboB0yPiIklXpHN/l2xCqbMj4i1Jw4CbgSOb8GM02ywHxbalq6RX0vpTwDiyZu0LETEvpQ8H9q19Xgj0BAYDhwN3R0Q18J6kxzdz/kOAqbXnioj6vit4NDBEqqsI9pC0bbrGP6Zj/1fS8jzu6QJJx6f1AamsS4Ea4N6U/j/Ag+kaXwLuz7l25zyuYZY3B8W2ZU1E7J+bkILDqtwk4PyImLxJvmObsRxlwCER8dlmypI3SUeQBdhDI2K1pCeBLvVkj3Tdjzf9GZg1Jz9TLD2TgXMkdQSQtLukbsBU4OT0zHEH4MubOfZ54HBJg9KxvVP6J0D3nHyPAg6ifaYAAADJSURBVOfXbkiqDVJTgdNS2jFARSNl7QksTwFxT7Kaaq0yoLa2expZs3wlME/SiekakrRfI9cwK4iDYum5jex54Utp8qX/JmsRPAS8lfbdSfYlmI1ExEfAWWRN1VfZ0Hz9A3B8bUcLcAEwNHXkzGRDL/iVZEH1DbJm9PxGyjoJ6CBpFnANWVCutQo4ON3DkcBVKf3rwJmpfG/gKR6smfkrOWZmOVxTNDPL4aBoZpbDQdHMLIeDoplZDgdFM7McDopmZjkcFM3Mcvx/uuSdjEkq4ckAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "plot_confusion_matrix(model_smote_scaled, X_test_scaled, y_test) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predicted_smote_scaled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDdtzq1dOhYf",
        "outputId": "0dcf4b4f-010f-4e85-96bd-7bc2262098f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.86      0.91     15981\n",
            "           1       0.50      0.81      0.62      2775\n",
            "\n",
            "    accuracy                           0.85     18756\n",
            "   macro avg       0.73      0.83      0.76     18756\n",
            "weighted avg       0.89      0.85      0.87     18756\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}